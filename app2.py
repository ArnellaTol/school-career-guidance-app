import streamlit as st
import pandas as pd
import numpy as np
import joblib
import requests
import os
import json
import logging
from dotenv import load_dotenv
from huggingface_hub import InferenceClient, login
from sentence_transformers import SentenceTransformer
from annoy import AnnoyIndex
from streamlit_option_menu import option_menu

# ==========================
#  CONFIG
# ==========================
st.set_page_config(page_title="AI-powered program for school career guidance")
logging.basicConfig(level=logging.DEBUG)
load_dotenv()

# ==========================
#  GLOBAL DATA
# ==========================
out_col_names = ['signsystem', 'technology', 'nature', 'artistic', 'human', 'business']
inp_col_names = [
    'kaz_lang_7', 'liter_7', 'rus_lang_7', 'eng_lang_7', 'math_7', 'comps_7',
    'kaz_hist_7', 'art_7', 'pe_7', 'geography_7', 'biology_7', 'chemistry_7',
    'physics_7', 'world_hist_7', 'Activist', 'Career', 'Tester', 'Creator',
    'Designer', 'Researcher', 'kaz_lang_8', 'liter_8', 'rus_lang_8', 'eng_lang_8',
    'math_8', 'comps_8', 'kaz_hist_8', 'art_8', 'pe_8', 'geography_8', 'biology_8',
    'chemistry_8', 'physics_8', 'world_hist_8', 'kaz_lang_9', 'liter_9', 'rus_lang_9',
    'eng_lang_9', 'math_9', 'comps_9', 'kaz_hist_9', 'art_9', 'pe_9', 'geography_9',
    'biology_9', 'chemistry_9', 'physics_9', 'world_hist_9', 'rights_9', 'kaz_lang_10',
    'liter_10', 'rus_lang_10', 'eng_lang_10', 'math_10', 'comps_10', 'kaz_hist_10',
    'art_10', 'pe_10', 'geography_10', 'biology_10', 'chemistry_10', 'physics_10',
    'world_hist_10'
]

checkbox_columns = [ 'Activist', 'Career', 'Tester', 'Creator', 'Designer', 'Researcher' ]

# —Ç–∏–ø—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–π
type_columns = {
    'class_0': 'Person-Sign System',
    'class_1': 'Person-Technology',
    'class_2': 'Person-Nature',
    'class_3': 'Person-Artistic Image',
    'class_4': 'Person-Person',
    'class_5': 'Person-Business'
}
type_columns_ru = {
    'class_0': '–ß–µ–ª–æ–≤–µ–∫-–ó–Ω–∞–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞',
    'class_1': '–ß–µ–ª–æ–≤–µ–∫-–¢–µ—Ö–Ω–∏–∫–∞',
    'class_2': '–ß–µ–ª–æ–≤–µ–∫-–ü—Ä–∏—Ä–æ–¥–∞',
    'class_3': '–ß–µ–ª–æ–≤–µ–∫-–•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –æ–±—Ä–∞–∑',
    'class_4': '–ß–µ–ª–æ–≤–µ–∫-–ß–µ–ª–æ–≤–µ–∫',
    'class_5': '–ß–µ–ª–æ–≤–µ–∫-–ë–∏–∑–Ω–µ—Å'
}
type_columns_kz = {
    'class_0': '–ê–¥–∞–º-–ë–µ–ª–≥—ñ–ª—ñ–∫ –∂“Ø–π–µ',
    'class_1': '–ê–¥–∞–º-–¢–µ—Ö–Ω–∏–∫–∞',
    'class_2': '–ê–¥–∞–º-–¢–∞–±–∏“ì–∞—Ç',
    'class_3': '–ê–¥–∞–º-–ö”©—Ä–∫–µ–º –±–µ–π–Ω–µ',
    'class_4': '–ê–¥–∞–º-–ê–¥–∞–º',
    'class_5': '–ê–¥–∞–º-–ë–∏–∑–Ω–µ—Å'
}

thresholds = {
    'class_0': 0.39,
    'class_1': 0.30903005409623036,
    'class_2': 0.23611111111111113,
    'class_3': 0.44833333333333336,
    'class_4': 0.13,
    'class_5': 0.17
}

column_names_dict = { 'kaz_lang_7': 'Kazakh Language', 'liter_7': 'Literature', 'rus_lang_7': 'Russian Language', 'eng_lang_7': 'English Language', 'math_7': 'Mathematics', 'comps_7': 'Informatics', 'kaz_hist_7': 'History of Kazakhstan', 'art_7': 'Art', 'pe_7': 'Physical Education', 'geography_7': 'Geography', 'biology_7': 'Biology', 'chemistry_7': 'Chemistry', 'physics_7': 'Physics', 'world_hist_7': 'World History', 'Activist': 'Activist', 'Career': 'Careerist', 'Tester': 'Tester', 'Creator': 'Creator', 'Designer': 'Designer', 'Researcher': 'Researcher', 'kaz_lang_8': 'Kazakh Language', 'liter_8': 'Literature', 'rus_lang_8': 'Russian Language', 'eng_lang_8': 'English Language', 'math_8': 'Mathematics', 'comps_8': 'Informatics', 'kaz_hist_8': 'History of Kazakhstan', 'art_8': 'Art', 'pe_8': 'Physical Education', 'geography_8': 'Geography', 'biology_8': 'Biology', 'chemistry_8': 'Chemistry', 'physics_8': 'Physics', 'world_hist_8': 'World History', 'kaz_lang_9': 'Kazakh Language', 'liter_9': 'Literature', 'rus_lang_9': 'Russian Language', 'eng_lang_9': 'English Language', 'math_9': 'Mathematics', 'comps_9': 'Informatics', 'kaz_hist_9': 'History of Kazakhstan', 'art_9': 'Art', 'pe_9': 'Physical Education', 'geography_9': 'Geography', 'biology_9': 'Biology', 'chemistry_9': 'Chemistry', 'physics_9': 'Physics', 'world_hist_9': 'World History', 'rights_9': 'Law Fundamentals', 'kaz_lang_10': 'Kazakh Language', 'liter_10': 'Literature', 'rus_lang_10': 'Russian Language', 'eng_lang_10': 'English Language', 'math_10': 'Mathematics', 'comps_10': 'Informatics', 'kaz_hist_10': 'History of Kazakhstan', 'art_10': 'Art', 'pe_10': 'Physical Education', 'geography_10': 'Geography', 'biology_10': 'Biology', 'chemistry_10': 'Chemistry', 'physics_10': 'Physics', 'world_hist_10': 'World History' } 
column_names_dict_ru = { 'kaz_lang_7': '–ö–∞–∑–∞—Ö—Å–∫–∏–π —è–∑—ã–∫', 'liter_7': '–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', 'rus_lang_7': '–†—É—Å—Å–∫–∏–π —è–∑—ã–∫', 'eng_lang_7': '–ê–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫', 'math_7': '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞', 'comps_7': '–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞', 'kaz_hist_7': '–ò—Å—Ç–æ—Ä–∏—è –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞', 'art_7': '–ò—Å–∫—É—Å—Å—Ç–≤–æ', 'pe_7': '–§–∏–∑–∫—É–ª—å—Ç—É—Ä–∞', 'geography_7': '–ì–µ–æ–≥—Ä–∞—Ñ–∏—è', 'biology_7': '–ë–∏–æ–ª–æ–≥–∏—è', 'chemistry_7': '–•–∏–º–∏—è', 'physics_7': '–§–∏–∑–∏–∫–∞', 'world_hist_7': '–í—Å–µ–º–∏—Ä–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è', 'Activist': '–ê–∫—Ç–∏–≤–∏—Å—Ç', 'Career': '–ö–∞—Ä—å–µ—Ä–∏—Å—Ç', 'Tester': '–ò—Å–ø—ã—Ç–∞—Ç–µ–ª—å', 'Creator': '–¢–≤–æ—Ä–µ—Ü', 'Designer': '–ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤—â–∏–∫', 'Researcher': '–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å', 'kaz_lang_8': '–ö–∞–∑–∞—Ö—Å–∫–∏–π —è–∑—ã–∫', 'liter_8': '–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', 'rus_lang_8': '–†—É—Å—Å–∫–∏–π —è–∑—ã–∫', 'eng_lang_8': '–ê–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫', 'math_8': '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞', 'comps_8': '–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞', 'kaz_hist_8': '–ò—Å—Ç–æ—Ä–∏—è –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞', 'art_8': '–ò—Å–∫—É—Å—Å—Ç–≤–æ', 'pe_8': '–§–∏–∑–∫—É–ª—å—Ç—É—Ä–∞', 'geography_8': '–ì–µ–æ–≥—Ä–∞—Ñ–∏—è', 'biology_8': '–ë–∏–æ–ª–æ–≥–∏—è', 'chemistry_8': '–•–∏–º–∏—è', 'physics_8': '–§–∏–∑–∏–∫–∞', 'world_hist_8': '–í—Å–µ–º–∏—Ä–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è', 'kaz_lang_9': '–ö–∞–∑–∞—Ö—Å–∫–∏–π —è–∑—ã–∫', 'liter_9': '–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', 'rus_lang_9': '–†—É—Å—Å–∫–∏–π —è–∑—ã–∫', 'eng_lang_9': '–ê–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫', 'math_9': '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞', 'comps_9': '–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞', 'kaz_hist_9': '–ò—Å—Ç–æ—Ä–∏—è –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞', 'art_9': '–ò—Å–∫—É—Å—Å—Ç–≤–æ', 'pe_9': '–§–∏–∑–∫—É–ª—å—Ç—É—Ä–∞', 'geography_9': '–ì–µ–æ–≥—Ä–∞—Ñ–∏—è', 'biology_9': '–ë–∏–æ–ª–æ–≥–∏—è', 'chemistry_9': '–•–∏–º–∏—è', 'physics_9': '–§–∏–∑–∏–∫–∞', 'world_hist_9': '–í—Å–µ–º–∏—Ä–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è', 'rights_9': '–û—Å–Ω–æ–≤—ã –ø—Ä–∞–≤–∞', 'kaz_lang_10': '–ö–∞–∑–∞—Ö—Å–∫–∏–π —è–∑—ã–∫', 'liter_10': '–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', 'rus_lang_10': '–†—É—Å—Å–∫–∏–π —è–∑—ã–∫', 'eng_lang_10': '–ê–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫', 'math_10': '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞', 'comps_10': '–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞', 'kaz_hist_10': '–ò—Å—Ç–æ—Ä–∏—è –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞', 'art_10': '–ò—Å–∫—É—Å—Å—Ç–≤–æ', 'pe_10': '–§–∏–∑–∫—É–ª—å—Ç—É—Ä–∞', 'geography_10': '–ì–µ–æ–≥—Ä–∞—Ñ–∏—è', 'biology_10': '–ë–∏–æ–ª–æ–≥–∏—è', 'chemistry_10': '–•–∏–º–∏—è', 'physics_10': '–§–∏–∑–∏–∫–∞', 'world_hist_10': '–í—Å–µ–º–∏—Ä–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è' } 
column_names_dict_kz = {
    'kaz_lang_7': '“ö–∞–∑–∞“õ —Ç—ñ–ª—ñ',
    'liter_7': '”ò–¥–µ–±–∏–µ—Ç',
    'rus_lang_7': '–û—Ä—ã—Å —Ç—ñ–ª—ñ',
    'eng_lang_7': '–ê“ì—ã–ª—à—ã–Ω —Ç—ñ–ª—ñ',
    'math_7': '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞',
    'comps_7': '–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞',
    'kaz_hist_7': '“ö–∞–∑–∞“õ—Å—Ç–∞–Ω —Ç–∞—Ä–∏—Ö—ã',
    'art_7': '–ë–µ–π–Ω–µ–ª–µ—É ”©–Ω–µ—Ä—ñ',
    'pe_7': '–î–µ–Ω–µ —à—ã–Ω—ã“õ—Ç—ã—Ä—É',
    'geography_7': '–ì–µ–æ–≥—Ä–∞—Ñ–∏—è',
    'biology_7': '–ë–∏–æ–ª–æ–≥–∏—è',
    'chemistry_7': '–•–∏–º–∏—è',
    'physics_7': '–§–∏–∑–∏–∫–∞',
    'world_hist_7': '–î“Ø–Ω–∏–µ–∂“Ø–∑—ñ —Ç–∞—Ä–∏—Ö—ã',

    'Activist': '–ë–µ–ª—Å–µ–Ω–¥—ñ',
    'Career': '–ú–∞–º–∞–Ω–¥—ã“õ —Ç–∞“£–¥–∞—É—à—ã',
    'Tester': '–¢–µ–∫—Å–µ—Ä—É—à—ñ',
    'Creator': '–ñ–∞—Å–∞—É—à—ã',
    'Designer': '–î–∏–∑–∞–π–Ω–µ—Ä',
    'Researcher': '–ó–µ—Ä—Ç—Ç–µ—É—à—ñ',

    'kaz_lang_8': '“ö–∞–∑–∞“õ —Ç—ñ–ª—ñ',
    'liter_8': '”ò–¥–µ–±–∏–µ—Ç',
    'rus_lang_8': '–û—Ä—ã—Å —Ç—ñ–ª—ñ',
    'eng_lang_8': '–ê“ì—ã–ª—à—ã–Ω —Ç—ñ–ª—ñ',
    'math_8': '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞',
    'comps_8': '–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞',
    'kaz_hist_8': '“ö–∞–∑–∞“õ—Å—Ç–∞–Ω —Ç–∞—Ä–∏—Ö—ã',
    'art_8': '–ë–µ–π–Ω–µ–ª–µ—É ”©–Ω–µ—Ä—ñ',
    'pe_8': '–î–µ–Ω–µ —à—ã–Ω—ã“õ—Ç—ã—Ä—É',
    'geography_8': '–ì–µ–æ–≥—Ä–∞—Ñ–∏—è',
    'biology_8': '–ë–∏–æ–ª–æ–≥–∏—è',
    'chemistry_8': '–•–∏–º–∏—è',
    'physics_8': '–§–∏–∑–∏–∫–∞',
    'world_hist_8': '–î“Ø–Ω–∏–µ–∂“Ø–∑—ñ —Ç–∞—Ä–∏—Ö—ã',

    'kaz_lang_9': '“ö–∞–∑–∞“õ —Ç—ñ–ª—ñ',
    'liter_9': '”ò–¥–µ–±–∏–µ—Ç',
    'rus_lang_9': '–û—Ä—ã—Å —Ç—ñ–ª—ñ',
    'eng_lang_9': '–ê“ì—ã–ª—à—ã–Ω —Ç—ñ–ª—ñ',
    'math_9': '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞',
    'comps_9': '–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞',
    'kaz_hist_9': '“ö–∞–∑–∞“õ—Å—Ç–∞–Ω —Ç–∞—Ä–∏—Ö—ã',
    'art_9': '–ë–µ–π–Ω–µ–ª–µ—É ”©–Ω–µ—Ä—ñ',
    'pe_9': '–î–µ–Ω–µ —à—ã–Ω—ã“õ—Ç—ã—Ä—É',
    'geography_9': '–ì–µ–æ–≥—Ä–∞—Ñ–∏—è',
    'biology_9': '–ë–∏–æ–ª–æ–≥–∏—è',
    'chemistry_9': '–•–∏–º–∏—è',
    'physics_9': '–§–∏–∑–∏–∫–∞',
    'world_hist_9': '–î“Ø–Ω–∏–µ–∂“Ø–∑—ñ —Ç–∞—Ä–∏—Ö—ã',
    'rights_9': '“ö“±“õ—ã“õ –Ω–µ–≥—ñ–∑–¥–µ—Ä—ñ',

    'kaz_lang_10': '“ö–∞–∑–∞“õ —Ç—ñ–ª—ñ',
    'liter_10': '”ò–¥–µ–±–∏–µ—Ç',
    'rus_lang_10': '–û—Ä—ã—Å —Ç—ñ–ª—ñ',
    'eng_lang_10': '–ê“ì—ã–ª—à—ã–Ω —Ç—ñ–ª—ñ',
    'math_10': '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞',
    'comps_10': '–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞',
    'kaz_hist_10': '“ö–∞–∑–∞“õ—Å—Ç–∞–Ω —Ç–∞—Ä–∏—Ö—ã',
    'art_10': '–ë–µ–π–Ω–µ–ª–µ—É ”©–Ω–µ—Ä—ñ',
    'pe_10': '–î–µ–Ω–µ —à—ã–Ω—ã“õ—Ç—ã—Ä—É',
    'geography_10': '–ì–µ–æ–≥—Ä–∞—Ñ–∏—è',
    'biology_10': '–ë–∏–æ–ª–æ–≥–∏—è',
    'chemistry_10': '–•–∏–º–∏—è',
    'physics_10': '–§–∏–∑–∏–∫–∞',
    'world_hist_10': '–î“Ø–Ω–∏–µ–∂“Ø–∑—ñ —Ç–∞—Ä–∏—Ö—ã'
}

lang_dicts = {
    "ru": {
        "expander": "–í–≤–µ–¥–∏—Ç–µ –æ—Ü–µ–Ω–∫–∏ –∑–∞ {grade} –∫–ª–∞—Å—Å:",
        "most_suitable": "–ù–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ç–∏–ø—ã:",
        "probability": "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å",
        "type": "–¢–∏–ø",
        "questions": [
            "**1. –ö–∞–∫–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç –Ω–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç?**",
            "**2. –ö–∞–∫–∏–µ –≤–∏–¥—ã –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∞–º —Ç–æ—á–Ω–æ –Ω–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã?**",
            "**3. –ë–µ–∑ —É—á–µ—Ç–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤, –∫–∞–∫–∏–µ –≤–∏–¥—ã –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–ª–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –≤–∞–º –Ω—Ä–∞–≤—è—Ç—Å—è?**",
            "**4. –ü–µ—Ä–µ—á–∏—Å–ª–∏—Ç–µ —Å–≤–æ–∏ —Ö–æ–±–±–∏ –∏ –∏–Ω—Ç–µ—Ä–µ—Å—ã:**",
            "**5. –ù–∞–∑–æ–≤–∏—Ç–µ —Ä–æ–ª–µ–≤—ã–µ –º–æ–¥–µ–ª–∏, —á—å–∏ –æ–±—Ä–∞–∑—ã –∂–∏–∑–Ω–∏ –∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤–∞—Å –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—Ç.**",
            "**6. –ö–∞–∫–∏–µ –∑–∞–¥–∞—á–∏ –ø—Ä–∏–¥–∞—é—Ç –≤–∞–º —ç–Ω–µ—Ä–≥–∏–∏?**",
            "**7. –ö–∞–∫–∏–µ –∑–∞–¥–∞—á–∏ –≤–∞—Å —É—Ç–æ–º–ª—è—é—Ç?**"
        ]
    },
    "en": {
        "expander": "Enter grades for grade {grade}:",
        "most_suitable": "Most suitable types:",
        "probability": "Probability",
        "type": "Type",
        "questions": [
            "**1. Which professions are you currently interested in?**",
            "**2. Which activities are you definitely not interested in?**",
            "**3. Regardless of finances, which activities or professions do you enjoy?**",
            "**4. List your hobbies and interests:**",
            "**5. Name role models whose lifestyles and achievements inspire you.**",
            "**6. Which tasks give you energy?**",
            "**7. Which tasks drain your energy?**"
        ]
    },
    "kz": {
        "expander": "{grade}-—Å—ã–Ω—ã–ø –±–∞“ì–∞–ª–∞—Ä—ã–Ω –µ–Ω–≥—ñ–∑—ñ“£—ñ–∑:",
        "most_suitable": "–ï“£ “õ–æ–ª–∞–π–ª—ã —Ç–∏–ø—Ç–µ—Ä:",
        "probability": "–´“õ—Ç–∏–º–∞–ª–¥—ã“õ",
        "type": "–¢“Ø—Ä—ñ",
        "questions": [
            "**1. “ö–∞–∑—ñ—Ä —Å—ñ–∑–¥—ñ “õ–∞–Ω–¥–∞–π –º–∞–º–∞–Ω–¥—ã“õ—Ç–∞—Ä “õ—ã–∑—ã“õ—Ç—ã—Ä–∞–¥—ã?**",
            "**2. –°—ñ–∑–≥–µ –º“Ø–ª–¥–µ–º “õ—ã–∑—ã“õ –µ–º–µ—Å —ñ—Å-”ô—Ä–µ–∫–µ—Ç—Ç–µ—Ä “õ–∞–Ω–¥–∞–π?**",
            "**3. “ö–∞—Ä–∂—ã–ª—ã“õ –∞—Å–ø–µ–∫—Ç—ñ–ª–µ—Ä–¥—ñ –µ—Å–µ–ø—Ç–µ–º–µ–≥–µ–Ω–¥–µ, “õ–∞–Ω–¥–∞–π —ñ—Å-”ô—Ä–µ–∫–µ—Ç—Ç–µ—Ä –Ω–µ–º–µ—Å–µ –º–∞–º–∞–Ω–¥—ã“õ—Ç–∞—Ä “±–Ω–∞–π–¥—ã?**",
            "**4. –•–æ–±–±–∏—ñ“£—ñ–∑ –±–µ–Ω “õ—ã–∑—ã“ì—É—à—ã–ª—ã“õ—Ç–∞—Ä—ã“£—ã–∑–¥—ã –∂–∞–∑—ã“£—ã–∑:**",
            "**5. –°—ñ–∑–¥—ñ ”©–º—ñ—Ä —Å–∞–ª—Ç—ã –º–µ–Ω –∂–µ—Ç—ñ—Å—Ç—ñ–∫—Ç–µ—Ä—ñ–º–µ–Ω —à–∞–±—ã—Ç—Ç–∞–Ω–¥—ã—Ä–∞—Ç—ã–Ω —Ç“±–ª“ì–∞–ª–∞—Ä–¥—ã –∞—Ç–∞“£—ã–∑.**",
            "**6. –°—ñ–∑–≥–µ –∫“Ø—à-“õ—É–∞—Ç –±–µ—Ä–µ—Ç—ñ–Ω —Ç–∞–ø—Å—ã—Ä–º–∞–ª–∞—Ä “õ–∞–Ω–¥–∞–π?**",
            "**7. –°—ñ–∑–¥—ñ —à–∞—Ä—à–∞—Ç–∞—Ç—ã–Ω —Ç–∞–ø—Å—ã—Ä–º–∞–ª–∞—Ä “õ–∞–Ω–¥–∞–π?**"
        ]
    }
}

# ==========================
#  HELPER FUNCTIONS
# ==========================
def create_expander(class_label, cols, lang_dict, column_names_dict):
    with st.expander(lang_dict["expander"].format(grade=class_label)):
        for col in cols:
            input_values[col] = st.number_input(
                column_names_dict[col], min_value=2, max_value=5, step=1, value=5, key=col
            )


def save_to_dataframe(selected_checkboxes, input_values):
    data = {**selected_checkboxes, **input_values}
    for key in checkbox_columns:
        data[key] = int(data.get(key, False))
    df = pd.DataFrame([data], columns=inp_col_names)
    return df

def apply_model(model_path, input_df):
    model = joblib.load(model_path)
    probabilities = model.predict_proba(input_df)
    if isinstance(probabilities, list):
        probabilities = np.array(probabilities)
    probability_dict = {f'class_{i}': probabilities[i][:, 1] for i in range(len(probabilities))}
    return pd.DataFrame(probability_dict)

def adjust_probabilities(probabilities, thresholds):
    return {key: min(100, (val / thresholds[key]) * 100) for key, val in probabilities.items()}

def display_results(df, lang_dict, type_columns_dict):
    results = {key: df[key].values[0] for key in df.columns}
    adjusted = adjust_probabilities(results, thresholds)
    selected_types = [type_columns_dict[k] for k, v in adjusted.items() if v >= 100]

    st.write(f"**{lang_dict['most_suitable']}**")
    for t in selected_types:
        st.write(f"- {t}")

    chart_data = pd.DataFrame({
        lang_dict["type"]: [type_columns_dict[k] for k in adjusted.keys()],
        lang_dict["probability"]: list(adjusted.values())
    })
    st.dataframe(chart_data, use_container_width=True)
    st.bar_chart(chart_data.set_index(lang_dict["type"]))


def get_ai_response(answers):
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {st.secrets['OPENAI_API_KEY']}", "Content-Type": "application/json"}
    data = {
        "model": "ft:gpt-4o-2024-08-06:personal::An4sVvnb",
        "messages": [
            {"role": "system", "content": "Assistant is an expert in career guidance..."},
            {"role": "user", "content": " ".join([f"{i+1}. {a}" for i, a in enumerate(answers)])}
        ],
        "max_tokens": 500
    }
    response = requests.post(url, headers=headers, json=data)
    response.raise_for_status()
    return response.json()["choices"][0]["message"]["content"]

@st.cache_data(show_spinner="Loading...")
def load_jsonl_files(folder_path):
    records = []
    for filename in os.listdir(folder_path):
        if filename.endswith(".jsonl"):
            with open(os.path.join(folder_path, filename), "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        records.append(json.loads(line))
                    except json.JSONDecodeError:
                        pass
    return records

def login_hf():
    if not os.environ.get("HF_TOKEN"):
        login(token=st.secrets["HF_TOKEN"])

@st.cache_resource
def load_annoy_index(rag_data):
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
    texts = [item["text"] for item in rag_data]
    index = AnnoyIndex(384, 'angular')
    index.load("index.ann")
    return embedder, index, texts

def generate_career_advice(question: str) -> str:
    messages = [
        {"role": "system", "content": 
         f"""You are a career advisor for high school students. 
         Student can ask different questions. In case of asking career paths suggestions, you need to select 3 career paths that are the best possible match for the student's stated interests, strengths, and dislikes.
         Keep the total response under 100 words. Be focused and relevant."""},
        {"role": "user", "content": question}
    ]
    client = InferenceClient( 
    provider="auto", 
    api_key=st.secrets["HF_TOKEN"])

    response = client.chat.completions.create(
    model="meta-llama/Meta-Llama-3-8B-Instruct",
    messages=messages,
    max_tokens=350,
    temperature=0.7
    )

    answer = response.choices[0].message.content

    return answer

def generate_rag_career_advice(question: str, embedder, annoy_index, texts: list, k: int = 5) -> str:    
    query_embedding = embedder.encode([question], convert_to_numpy=True)

    indices = annoy_index.get_nns_by_vector(query_embedding[0], k, include_distances=False)
    context_docs = [texts[i] for i in indices]

    context = "\n\n".join(context_docs)
    messages = [
        {"role": "system", "content": 
         f"""
You are a career advisor for high school students.

You have access to relevant background knowledge about career paths, student preferences, and educational strategies, shown below.

Context:
{context}

Your only task is to select 3 career paths that are the best possible match for the student's stated interests, strengths, and dislikes.
Strict instructions:
- Base your suggestions strictly on the student‚Äôs message. Do not invent or assume anything not mentioned.
- Recommend only career paths that clearly align with what the student enjoys and is good at, and that avoid what they dislike or find difficult.
- For each suggested path, explain in 3-4 sentences why it fits this student specifically.
- Do not give general advice or list unrelated options "just in case."
- Keep the total response under 350 words. Be focused and relevant.

If student asks other questions, answer them directly (still use the background context) and do not generate career paths if not asked.
"""},
        {"role": "user", "content": question}
    ]

    client = InferenceClient(
    provider="auto",  
    api_key=st.secrets["HF_TOKEN"])

    response = client.chat.completions.create(
    model="meta-llama/Meta-Llama-3-8B-Instruct",
    messages=messages,
    max_tokens=500,
    temperature=0.7
    )

    answer = response.choices[0].message.content

    if not answer.endswith("."):
        last_period = answer.rfind(".")
        if last_period != -1:
            answer = answer[:last_period + 1]
        else:
            answer = answer.strip()

    return answer


# ==========================
#  TRANSLATIONS
# ==========================
translations = {
    "en": {
        "header": "AI program for school career guidance",
        "tab1": "School grades",
        "tab2": "Open questions",
        "tab3": "AI career assistant",
        "choose_type": "Choose your motivational type:",
        "get_result": "Get result",
        "most_suitable": "Most suitable types:",
        "get_answer": "Get answer",
        "ai_response": "AI Response:",
        "advisor": "üéì Career Guidance AI Assistant",
        "student_question": "Enter your question:",
        "rag_toggle": "Enable RAG",
        "get_advice": "Get advice",
        "base_model": "üí° Base model",
        "rag_model": "üìö Model with RAG",
        "expander": "Grades for {grade} grade",
        "questions": [
            "1. Which professions are you currently interested in?",
            "2. Which activities are you definitely not interested in?",
            "3. Ignoring financial aspects, which activities or professions do you enjoy?",
            "4. List your hobbies and interests:",
            "5. Name role models whose lifestyle and achievements inspire you.",
            "6. Which tasks give you energy?",
            "7. Which tasks drain your energy?"
        ]
    },
    "ru": {
        "header": "–ò–ò –ø—Ä–æ–≥—Ä–∞–º–º–∞ –¥–ª—è —à–∫–æ–ª—å–Ω–æ–π –ø—Ä–æ—Ñ–æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏",
        "tab1": "–®–∫–æ–ª—å–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏",
        "tab2": "–û—Ç–∫—Ä—ã—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã",
        "tab3": "AI –ø—Ä–æ—Ñ–æ—Ä–∏–µ–Ω—Ç–∞—Ç–æ—Ä",
        "choose_type": "–í—ã–±–µ—Ä–∏—Ç–µ —Å–≤–æ–π –º–æ—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–∏–ø:",
        "get_result": "–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
        "most_suitable": "–ù–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ç–∏–ø—ã:",
        "get_answer": "–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç",
        "ai_response": "–û—Ç–≤–µ—Ç –ò–ò:",
        "advisor": "üéì –ü—Ä–æ—Ñ–æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–æ–Ω–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç",
        "student_question": "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:",
        "rag_toggle": "–í–∫–ª—é—á–∏—Ç—å RAG",
        "get_advice": "–ü–æ–ª—É—á–∏—Ç—å —Å–æ–≤–µ—Ç",
        "base_model": "üí° –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å",
        "rag_model": "üìö –ú–æ–¥–µ–ª—å —Å RAG",
        "expander": "–û—Ü–µ–Ω–∫–∏ –∑–∞ {grade} –∫–ª–∞—Å—Å",
        "questions": [
            "1. –ö–∞–∫–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç –Ω–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç?",
            "2. –ö–∞–∫–∏–µ –≤–∏–¥—ã –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∞–º —Ç–æ—á–Ω–æ –Ω–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã?",
            "3. –ë–µ–∑ —É—á–µ—Ç–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤, –∫–∞–∫–∏–µ –≤–∏–¥—ã –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–ª–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –≤–∞–º –Ω—Ä–∞–≤—è—Ç—Å—è?",
            "4. –ü–µ—Ä–µ—á–∏—Å–ª–∏—Ç–µ —Å–≤–æ–∏ —Ö–æ–±–±–∏ –∏ –∏–Ω—Ç–µ—Ä–µ—Å—ã:",
            "5. –ù–∞–∑–æ–≤–∏—Ç–µ —Ä–æ–ª–µ–≤—ã–µ –º–æ–¥–µ–ª–∏, —á—å–∏ –æ–±—Ä–∞–∑—ã –∂–∏–∑–Ω–∏ –∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤–∞—Å –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—Ç.",
            "6. –ö–∞–∫–∏–µ –∑–∞–¥–∞—á–∏ –ø—Ä–∏–¥–∞—é—Ç –≤–∞–º —ç–Ω–µ—Ä–≥–∏–∏?",
            "7. –ö–∞–∫–∏–µ –∑–∞–¥–∞—á–∏ –≤–∞—Å —É—Ç–æ–º–ª—è—é—Ç?"
        ]
    },
    "kz": {
        "header": "–ú–µ–∫—Ç–µ–ø—Ç—ñ–∫ –∫”ô—Å—ñ–±–∏ –±–∞“ì–¥–∞—Ä –±–µ—Ä—É–≥–µ –∞—Ä–Ω–∞–ª“ì–∞–Ω –ñ–ò –±–∞“ì–¥–∞—Ä–ª–∞–º–∞",
        "tab1": "–ú–µ–∫—Ç–µ–ø –±–∞“ì–∞–ª–∞—Ä—ã",
        "tab2": "–ê—à—ã“õ —Å“±—Ä–∞“õ—Ç–∞—Ä",
        "tab3": "–ñ–ò –∫”ô—Å—ñ–±–∏ –±–∞“ì–¥–∞—Ä—à—ã",
        "choose_type": "”®–∑ –º–æ—Ç–∏–≤–∞—Ü–∏—è–ª—ã“õ —Ç–∏–ø—ñ“£—ñ–∑–¥—ñ —Ç–∞“£–¥–∞“£—ã–∑:",
        "get_result": "–ù”ô—Ç–∏–∂–µ –∞–ª—É",
        "most_suitable": "–ï“£ “õ–æ–ª–∞–π–ª—ã —Ç–∏–ø—Ç–µ—Ä:",
        "get_answer": "–ñ–∞—É–∞–ø –∞–ª—É",
        "ai_response": "–ñ–ò –∂–∞—É–∞–±—ã:",
        "advisor": "üéì –ö”ô—Å—ñ–±–∏ –±–∞“ì–¥–∞—Ä –±–µ—Ä–µ—Ç—ñ–Ω –ñ–ò –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—ñ",
        "student_question": "–°“±—Ä–∞“ì—ã“£—ã–∑–¥—ã –µ–Ω–≥—ñ–∑—ñ“£—ñ–∑:",
        "rag_toggle": "RAG “õ–æ—Å—É",
        "get_advice": "–ö–µ“£–µ—Å –∞–ª—É",
        "base_model": "üí° –ù–µ–≥—ñ–∑–≥—ñ –º–æ–¥–µ–ª—å",
        "rag_model": "üìö RAG –º–æ–¥–µ–ª—ñ",
        "expander": "{grade} —Å—ã–Ω—ã–ø –±–∞“ì–∞–ª–∞—Ä—ã",
        "questions": [
            "1. “ö–∞–Ω–¥–∞–π –º–∞–º–∞–Ω–¥—ã“õ—Ç–∞—Ä“ì–∞ “õ–∞–∑—ñ—Ä “õ—ã–∑—ã“ì—É—à—ã–ª—ã“õ —Ç–∞–Ω—ã—Ç–∞—Å—ã–∑?",
            "2. “ö–∞–π “õ—ã–∑–º–µ—Ç —Ç“Ø—Ä–ª–µ—Ä—ñ —Å—ñ–∑–≥–µ –º“Ø–ª–¥–µ “õ—ã–∑—ã“õ—Å—ã–∑?",
            "3. “ö–∞—Ä–∂—ã–ª—ã“õ –∞—Å–ø–µ–∫—Ç—ñ–ª–µ—Ä–¥—ñ –µ—Å–∫–µ—Ä–º–µ–π, “õ–∞–Ω–¥–∞–π “õ—ã–∑–º–µ—Ç —Ç“Ø—Ä–ª–µ—Ä—ñ –Ω–µ–º–µ—Å–µ –º–∞–º–∞–Ω–¥—ã“õ—Ç–∞—Ä “±–Ω–∞–π–¥—ã?",
            "4. –•–æ–±–±–∏ –º–µ–Ω “õ—ã–∑—ã“ì—É—à—ã–ª—ã“õ—Ç–∞—Ä—ã“£—ã–∑–¥—ã –∞—Ç–∞“£—ã–∑:",
            "5. ”®–º—ñ—Ä —Å–∞–ª—Ç—ã –º–µ–Ω –∂–µ—Ç—ñ—Å—Ç—ñ–∫—Ç–µ—Ä—ñ —Å—ñ–∑–¥—ñ —à–∞–±—ã—Ç—Ç–∞–Ω–¥—ã—Ä–∞—Ç—ã–Ω —Ç“±–ª“ì–∞–ª–∞—Ä–¥—ã –∞—Ç–∞“£—ã–∑.",
            "6. “ö–∞–π —Ç–∞–ø—Å—ã—Ä–º–∞–ª–∞—Ä —Å—ñ–∑–≥–µ “õ—É–∞—Ç –±–µ—Ä–µ–¥—ñ?",
            "7. “ö–∞–π —Ç–∞–ø—Å—ã—Ä–º–∞–ª–∞—Ä —Å—ñ–∑–¥—ñ —à–∞—Ä—à–∞—Ç–∞–¥—ã?"
        ]
    }
}

# ==========================
#  INTERFACE
# ==========================

# —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (label ‚Üí value)
lang_options = {
    "KZ": "kz",
    "EN": "en",
    "RU": "ru"
}

# —Å–µ–ª–µ–∫—Ç–æ—Ä –≤ —Å–∞–π–¥–±–∞—Ä–µ
lang_label = st.sidebar.selectbox(
    "üåê –í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ / Select language / –¢—ñ–ª–¥—ñ —Ç–∞“£–¥–∞“£—ã–∑",
    options=list(lang_options.keys()),   # —Ç–æ, —á—Ç–æ –≤–∏–¥–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (KZ EN RU)
    index=0   # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é KZ
)

# –ø–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
lang = lang_options[lang_label]
lang_dict = lang_dicts[lang]

# —Å–æ—Ö—Ä–∞–Ω—è–µ–º —è–∑—ã–∫ –≤ session_state
if "lang" not in st.session_state:
    st.session_state["lang"] = lang
else:
    st.session_state["lang"] = lang   # –æ–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–∏ —Å–º–µ–Ω–µ

t = translations[st.session_state["lang"]]
ld = lang_dicts[st.session_state["lang"]]


input_values = {}
rag_data = load_jsonl_files("./jsonl datafiles")
login_hf()
embedder, annoy_index, texts = load_annoy_index(rag_data)

# –≤—ã–±–æ—Ä —è–∑—ã–∫–∞ (–ø–æ–∑–∂–µ –º–æ–∂–Ω–æ –≤—ã–Ω–µ—Å—Ç–∏ –≤ sidebar)
lang = st.session_state.get("lang", "ru")
t = translations[lang]       # –∫–æ—Ä–æ—Ç–∫–∞—è —Å—Å—ã–ª–∫–∞
ld = lang_dicts[lang]        # –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤/—ç–∫—Å–ø–∞–Ω–¥–µ—Ä–æ–≤

st.header(t["header"])
tabs = st.tabs([t["tab1"], t["tab2"], t["tab3"]])

# –æ–±—â–∏–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —è–∑—ã–∫–æ–≤
column_names_dicts = {
    "ru": column_names_dict_ru,
    "en": column_names_dict,      # —Ç–≤–æ–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
    "kz": column_names_dict_kz
}

# –≤—ã–±–∏—Ä–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –ø–æ —è–∑—ã–∫—É
current_column_names = column_names_dicts[lang]

with tabs[0]:
    with st.form("grades_form"):
        st.write(f"**{t['choose_type']}**")
        selected_checkboxes = {
            col: st.checkbox(current_column_names[col]) for col in checkbox_columns
        }
        for grade in [7, 8, 9, 10]:
            create_expander(
                grade,
                [c for c in inp_col_names if c.endswith(f"_{grade}")],
                {"expander": t["expander"]},  # –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º —Ñ—Ä–∞–∑—É –∏–∑ –ø–µ—Ä–µ–≤–æ–¥–∞
                current_column_names          # ‚úÖ –ø–µ—Ä–µ–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –ø—Ä–µ–¥–º–µ—Ç–æ–≤
            )

        submit_tab1 = st.form_submit_button(t["get_result"])


# TAB 2
with tabs[1]:
    with st.form("open_questions_form"):
        user_answers = [
            st.text_input(q, key=f"answer_{i}") for i, q in enumerate(t["questions"])
        ]
        submit_tab2 = st.form_submit_button(t["get_answer"])

    if submit_tab2:
        ai_response = get_ai_response(user_answers)
        st.session_state["tab2_ai_response"] = ai_response

    if "tab2_ai_response" in st.session_state:
        st.write(t["ai_response"])
        st.write(st.session_state["tab2_ai_response"])


# TAB 3
with tabs[2]:
    with st.form("career_form"):
        st.title(t["advisor"])
        student_question = st.text_area(t["student_question"], height=100, key="student_q")
        use_rag = st.toggle(t["rag_toggle"], value=True)

        submit_tab3 = st.form_submit_button(t["get_advice"])

    if submit_tab3:
        if use_rag:
            st.session_state["tab3_base"] = generate_career_advice(student_question)
            st.session_state["tab3_rag"] = generate_rag_career_advice(student_question, embedder, annoy_index, texts)
        else:
            st.session_state["tab3_base"] = generate_career_advice(student_question)

    if "tab3_base" in st.session_state:
        st.subheader(t["base_model"])
        st.write(st.session_state["tab3_base"])
    if use_rag and "tab3_rag" in st.session_state:
        st.subheader(t["rag_model"])
        st.write(st.session_state["tab3_rag"])
