# app_fixed.py
import streamlit as st
import pandas as pd
import numpy as np
import joblib
import requests
import os
import json
import logging
from dotenv import load_dotenv
from huggingface_hub import InferenceClient, login
from sentence_transformers import SentenceTransformer
from annoy import AnnoyIndex
from streamlit_option_menu import option_menu
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
import io

# ==========================
#  CONFIG
# ==========================
st.set_page_config(page_title="AI-powered program for school career guidance")
logging.basicConfig(level=logging.DEBUG)
load_dotenv()

# ==========================
#  GLOBAL DATA
# ==========================
out_col_names = ['signsystem', 'technology', 'nature', 'artistic', 'human', 'business']
inp_col_names = [
    'kaz_lang_7', 'liter_7', 'rus_lang_7', 'eng_lang_7', 'math_7', 'comps_7',
    'kaz_hist_7', 'art_7', 'pe_7', 'geography_7', 'biology_7', 'chemistry_7',
    'physics_7', 'world_hist_7', 'Activist', 'Career', 'Tester', 'Creator',
    'Designer', 'Researcher', 'kaz_lang_8', 'liter_8', 'rus_lang_8', 'eng_lang_8',
    'math_8', 'comps_8', 'kaz_hist_8', 'art_8', 'pe_8', 'geography_8', 'biology_8',
    'chemistry_8', 'physics_8', 'world_hist_8', 'kaz_lang_9', 'liter_9', 'rus_lang_9',
    'eng_lang_9', 'math_9', 'comps_9', 'kaz_hist_9', 'art_9', 'pe_9', 'geography_9',
    'biology_9', 'chemistry_9', 'physics_9', 'world_hist_9', 'rights_9', 'kaz_lang_10',
    'liter_10', 'rus_lang_10', 'eng_lang_10', 'math_10', 'comps_10', 'kaz_hist_10',
    'art_10', 'pe_10', 'geography_10', 'biology_10', 'chemistry_10', 'physics_10',
    'world_hist_10'
]

checkbox_columns = ['Activist', 'Career', 'Tester', 'Creator', 'Designer', 'Researcher']

# Ñ‚Ð¸Ð¿Ñ‹ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¹
type_columns_en = {
    'class_0': 'Person-Sign System',
    'class_1': 'Person-Technology',
    'class_2': 'Person-Nature',
    'class_3': 'Person-Artistic Image',
    'class_4': 'Person-Person',
    'class_5': 'Person-Business'
}
type_columns_ru = {
    'class_0': 'Ð§ÐµÐ»Ð¾Ð²ÐµÐº-Ð—Ð½Ð°ÐºÐ¾Ð²Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð°',
    'class_1': 'Ð§ÐµÐ»Ð¾Ð²ÐµÐº-Ð¢ÐµÑ…Ð½Ð¸ÐºÐ°',
    'class_2': 'Ð§ÐµÐ»Ð¾Ð²ÐµÐº-ÐŸÑ€Ð¸Ñ€Ð¾Ð´Ð°',
    'class_3': 'Ð§ÐµÐ»Ð¾Ð²ÐµÐº-Ð¥ÑƒÐ´Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ð¾Ð±Ñ€Ð°Ð·',
    'class_4': 'Ð§ÐµÐ»Ð¾Ð²ÐµÐº-Ð§ÐµÐ»Ð¾Ð²ÐµÐº',
    'class_5': 'Ð§ÐµÐ»Ð¾Ð²ÐµÐº-Ð‘Ð¸Ð·Ð½ÐµÑ'
}
type_columns_kz = {
    'class_0': 'ÐÐ´Ð°Ð¼-Ð‘ÐµÐ»Ð³Ñ–Ð»Ñ–Ðº Ð¶Ò¯Ð¹Ðµ',
    'class_1': 'ÐÐ´Ð°Ð¼-Ð¢ÐµÑ…Ð½Ð¸ÐºÐ°',
    'class_2': 'ÐÐ´Ð°Ð¼-Ð¢Ð°Ð±Ð¸Ò“Ð°Ñ‚',
    'class_3': 'ÐÐ´Ð°Ð¼-ÐšÓ©Ñ€ÐºÐµÐ¼ Ð±ÐµÐ¹Ð½Ðµ',
    'class_4': 'ÐÐ´Ð°Ð¼-ÐÐ´Ð°Ð¼',
    'class_5': 'ÐÐ´Ð°Ð¼-Ð‘Ð¸Ð·Ð½ÐµÑ'
}

thresholds = {
    'class_0': 0.39,
    'class_1': 0.30903005409623036,
    'class_2': 0.23611111111111113,
    'class_3': 0.44833333333333336,
    'class_4': 0.13,
    'class_5': 0.17
}

# ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚Ð¾Ð² (en / ru / kz)
column_names_dict_en = {
    'kaz_lang_7': 'Kazakh Language', 'liter_7': 'Literature', 'rus_lang_7': 'Russian Language',
    'eng_lang_7': 'English Language', 'math_7': 'Mathematics', 'comps_7': 'Informatics',
    'kaz_hist_7': 'History of Kazakhstan', 'art_7': 'Art', 'pe_7': 'Physical Education',
    'geography_7': 'Geography', 'biology_7': 'Biology', 'chemistry_7': 'Chemistry',
    'physics_7': 'Physics', 'world_hist_7': 'World History',
    'Activist': 'Activist', 'Career': 'Careerist', 'Tester': 'Tester', 'Creator': 'Creator',
    'Designer': 'Designer', 'Researcher': 'Researcher',
    'kaz_lang_8': 'Kazakh Language', 'liter_8': 'Literature', 'rus_lang_8': 'Russian Language',
    'eng_lang_8': 'English Language', 'math_8': 'Mathematics', 'comps_8': 'Informatics',
    'kaz_hist_8': 'History of Kazakhstan', 'art_8': 'Art', 'pe_8': 'Physical Education',
    'geography_8': 'Geography', 'biology_8': 'Biology', 'chemistry_8': 'Chemistry',
    'physics_8': 'Physics', 'world_hist_8': 'World History',
    'kaz_lang_9': 'Kazakh Language', 'liter_9': 'Literature', 'rus_lang_9': 'Russian Language',
    'eng_lang_9': 'English Language', 'math_9': 'Mathematics', 'comps_9': 'Informatics',
    'kaz_hist_9': 'History of Kazakhstan', 'art_9': 'Art', 'pe_9': 'Physical Education',
    'geography_9': 'Geography', 'biology_9': 'Biology', 'chemistry_9': 'Chemistry',
    'physics_9': 'Physics', 'world_hist_9': 'World History', 'rights_9': 'Law Fundamentals',
    'kaz_lang_10': 'Kazakh Language', 'liter_10': 'Literature', 'rus_lang_10': 'Russian Language',
    'eng_lang_10': 'English Language', 'math_10': 'Mathematics', 'comps_10': 'Informatics',
    'kaz_hist_10': 'History of Kazakhstan', 'art_10': 'Art', 'pe_10': 'Physical Education',
    'geography_10': 'Geography', 'biology_10': 'Biology', 'chemistry_10': 'Chemistry',
    'physics_10': 'Physics', 'world_hist_10': 'World History'
}
column_names_dict_ru = {
    'kaz_lang_7': 'ÐšÐ°Ð·Ð°Ñ…ÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº', 'liter_7': 'Ð›Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°', 'rus_lang_7': 'Ð ÑƒÑÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº',
    'eng_lang_7': 'ÐÐ½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº', 'math_7': 'ÐœÐ°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐ°', 'comps_7': 'Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ÐºÐ°',
    'kaz_hist_7': 'Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ ÐšÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½Ð°', 'art_7': 'Ð˜ÑÐºÑƒÑÑÑ‚Ð²Ð¾', 'pe_7': 'Ð¤Ð¸Ð·ÐºÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð°',
    'geography_7': 'Ð“ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ', 'biology_7': 'Ð‘Ð¸Ð¾Ð»Ð¾Ð³Ð¸Ñ', 'chemistry_7': 'Ð¥Ð¸Ð¼Ð¸Ñ',
    'physics_7': 'Ð¤Ð¸Ð·Ð¸ÐºÐ°', 'world_hist_7': 'Ð’ÑÐµÐ¼Ð¸Ñ€Ð½Ð°Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ',
    'Activist': 'ÐÐºÑ‚Ð¸Ð²Ð¸ÑÑ‚', 'Career': 'ÐšÐ°Ñ€ÑŒÐµÑ€Ð¸ÑÑ‚', 'Tester': 'Ð˜ÑÐ¿Ñ‹Ñ‚Ð°Ñ‚ÐµÐ»ÑŒ', 'Creator': 'Ð¢Ð²Ð¾Ñ€ÐµÑ†',
    'Designer': 'ÐŸÑ€Ð¾ÐµÐºÑ‚Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº', 'Researcher': 'Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ',
    'kaz_lang_8': 'ÐšÐ°Ð·Ð°Ñ…ÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº', 'liter_8': 'Ð›Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°', 'rus_lang_8': 'Ð ÑƒÑÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº',
    'eng_lang_8': 'ÐÐ½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº', 'math_8': 'ÐœÐ°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐ°', 'comps_8': 'Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ÐºÐ°',
    'kaz_hist_8': 'Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ ÐšÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½Ð°', 'art_8': 'Ð˜ÑÐºÑƒÑÑÑ‚Ð²Ð¾', 'pe_8': 'Ð¤Ð¸Ð·ÐºÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð°',
    'geography_8': 'Ð“ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ', 'biology_8': 'Ð‘Ð¸Ð¾Ð»Ð¾Ð³Ð¸Ñ', 'chemistry_8': 'Ð¥Ð¸Ð¼Ð¸Ñ',
    'physics_8': 'Ð¤Ð¸Ð·Ð¸ÐºÐ°', 'world_hist_8': 'Ð’ÑÐµÐ¼Ð¸Ñ€Ð½Ð°Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ',
    'kaz_lang_9': 'ÐšÐ°Ð·Ð°Ñ…ÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº', 'liter_9': 'Ð›Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°', 'rus_lang_9': 'Ð ÑƒÑÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº',
    'eng_lang_9': 'ÐÐ½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº', 'math_9': 'ÐœÐ°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐ°', 'comps_9': 'Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ÐºÐ°',
    'kaz_hist_9': 'Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ ÐšÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½Ð°', 'art_9': 'Ð˜ÑÐºÑƒÑÑÑ‚Ð²Ð¾', 'pe_9': 'Ð¤Ð¸Ð·ÐºÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð°',
    'geography_9': 'Ð“ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ', 'biology_9': 'Ð‘Ð¸Ð¾Ð»Ð¾Ð³Ð¸Ñ', 'chemistry_9': 'Ð¥Ð¸Ð¼Ð¸Ñ',
    'physics_9': 'Ð¤Ð¸Ð·Ð¸ÐºÐ°', 'world_hist_9': 'Ð’ÑÐµÐ¼Ð¸Ñ€Ð½Ð°Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ', 'rights_9': 'ÐžÑÐ½Ð¾Ð²Ñ‹ Ð¿Ñ€Ð°Ð²Ð°',
    'kaz_lang_10': 'ÐšÐ°Ð·Ð°Ñ…ÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº', 'liter_10': 'Ð›Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°', 'rus_lang_10': 'Ð ÑƒÑÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº',
    'eng_lang_10': 'ÐÐ½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº', 'math_10': 'ÐœÐ°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐ°', 'comps_10': 'Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ÐºÐ°',
    'kaz_hist_10': 'Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ ÐšÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½Ð°', 'art_10': 'Ð˜ÑÐºÑƒÑÑÑ‚Ð²Ð¾', 'pe_10': 'Ð¤Ð¸Ð·ÐºÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð°',
    'geography_10': 'Ð“ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ', 'biology_10': 'Ð‘Ð¸Ð¾Ð»Ð¾Ð³Ð¸Ñ', 'chemistry_10': 'Ð¥Ð¸Ð¼Ð¸Ñ',
    'physics_10': 'Ð¤Ð¸Ð·Ð¸ÐºÐ°', 'world_hist_10': 'Ð’ÑÐµÐ¼Ð¸Ñ€Ð½Ð°Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ'
}
column_names_dict_kz = {
    'kaz_lang_7': 'ÒšÐ°Ð·Ð°Ò› Ñ‚Ñ–Ð»Ñ–', 'liter_7': 'Ó˜Ð´ÐµÐ±Ð¸ÐµÑ‚', 'rus_lang_7': 'ÐžÑ€Ñ‹Ñ Ñ‚Ñ–Ð»Ñ–',
    'eng_lang_7': 'ÐÒ“Ñ‹Ð»ÑˆÑ‹Ð½ Ñ‚Ñ–Ð»Ñ–', 'math_7': 'ÐœÐ°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐ°', 'comps_7': 'Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ÐºÐ°',
    'kaz_hist_7': 'ÒšÐ°Ð·Ð°Ò›ÑÑ‚Ð°Ð½ Ñ‚Ð°Ñ€Ð¸Ñ…Ñ‹', 'art_7': 'Ð‘ÐµÐ¹Ð½ÐµÐ»ÐµÑƒ Ó©Ð½ÐµÑ€Ñ–', 'pe_7': 'Ð”ÐµÐ½Ðµ ÑˆÑ‹Ð½Ñ‹Ò›Ñ‚Ñ‹Ñ€Ñƒ',
    'geography_7': 'Ð“ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ', 'biology_7': 'Ð‘Ð¸Ð¾Ð»Ð¾Ð³Ð¸Ñ', 'chemistry_7': 'Ð¥Ð¸Ð¼Ð¸Ñ',
    'physics_7': 'Ð¤Ð¸Ð·Ð¸ÐºÐ°', 'world_hist_7': 'Ð”Ò¯Ð½Ð¸ÐµÐ¶Ò¯Ð·Ñ– Ñ‚Ð°Ñ€Ð¸Ñ…Ñ‹',
    'Activist': 'Ð‘ÐµÐ»ÑÐµÐ½Ð´Ñ–', 'Career': 'ÐœÐ°Ð¼Ð°Ð½Ð´Ñ‹Ò› Ñ‚Ð°Ò£Ð´Ð°ÑƒÑˆÑ‹', 'Tester': 'Ð¢ÐµÐºÑÐµÑ€ÑƒÑˆÑ–',
    'Creator': 'Ð–Ð°ÑÐ°ÑƒÑˆÑ‹', 'Designer': 'Ð”Ð¸Ð·Ð°Ð¹Ð½ÐµÑ€', 'Researcher': 'Ð—ÐµÑ€Ñ‚Ñ‚ÐµÑƒÑˆÑ–',
    'kaz_lang_8': 'ÒšÐ°Ð·Ð°Ò› Ñ‚Ñ–Ð»Ñ–', 'liter_8': 'Ó˜Ð´ÐµÐ±Ð¸ÐµÑ‚', 'rus_lang_8': 'ÐžÑ€Ñ‹Ñ Ñ‚Ñ–Ð»Ñ–',
    'eng_lang_8': 'ÐÒ“Ñ‹Ð»ÑˆÑ‹Ð½ Ñ‚Ñ–Ð»Ñ–', 'math_8': 'ÐœÐ°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐ°', 'comps_8': 'Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ÐºÐ°',
    'kaz_hist_8': 'ÒšÐ°Ð·Ð°Ò›ÑÑ‚Ð°Ð½ Ñ‚Ð°Ñ€Ð¸Ñ…Ñ‹', 'art_8': 'Ð‘ÐµÐ¹Ð½ÐµÐ»ÐµÑƒ Ó©Ð½ÐµÑ€Ñ–', 'pe_8': 'Ð”ÐµÐ½Ðµ ÑˆÑ‹Ð½Ñ‹Ò›Ñ‚Ñ‹Ñ€Ñƒ',
    'geography_8': 'Ð“ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ', 'biology_8': 'Ð‘Ð¸Ð¾Ð»Ð¾Ð³Ð¸Ñ', 'chemistry_8': 'Ð¥Ð¸Ð¼Ð¸Ñ',
    'physics_8': 'Ð¤Ð¸Ð·Ð¸ÐºÐ°', 'world_hist_8': 'Ð”Ò¯Ð½Ð¸ÐµÐ¶Ò¯Ð·Ñ– Ñ‚Ð°Ñ€Ð¸Ñ…Ñ‹',
    'kaz_lang_9': 'ÒšÐ°Ð·Ð°Ò› Ñ‚Ñ–Ð»Ñ–', 'liter_9': 'Ó˜Ð´ÐµÐ±Ð¸ÐµÑ‚', 'rus_lang_9': 'ÐžÑ€Ñ‹Ñ Ñ‚Ñ–Ð»Ñ–',
    'eng_lang_9': 'ÐÒ“Ñ‹Ð»ÑˆÑ‹Ð½ Ñ‚Ñ–Ð»Ñ–', 'math_9': 'ÐœÐ°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐ°', 'comps_9': 'Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ÐºÐ°',
    'kaz_hist_9': 'ÒšÐ°Ð·Ð°Ò›ÑÑ‚Ð°Ð½ Ñ‚Ð°Ñ€Ð¸Ñ…Ñ‹', 'art_9': 'Ð‘ÐµÐ¹Ð½ÐµÐ»ÐµÑƒ Ó©Ð½ÐµÑ€Ñ–', 'pe_9': 'Ð”ÐµÐ½Ðµ ÑˆÑ‹Ð½Ñ‹Ò›Ñ‚Ñ‹Ñ€Ñƒ',
    'geography_9': 'Ð“ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ', 'biology_9': 'Ð‘Ð¸Ð¾Ð»Ð¾Ð³Ð¸Ñ', 'chemistry_9': 'Ð¥Ð¸Ð¼Ð¸Ñ',
    'physics_9': 'Ð¤Ð¸Ð·Ð¸ÐºÐ°', 'world_hist_9': 'Ð”Ò¯Ð½Ð¸ÐµÐ¶Ò¯Ð·Ñ– Ñ‚Ð°Ñ€Ð¸Ñ…Ñ‹', 'rights_9': 'ÒšÒ±Ò›Ñ‹Ò› Ð½ÐµÐ³Ñ–Ð·Ð´ÐµÑ€Ñ–',
    'kaz_lang_10': 'ÒšÐ°Ð·Ð°Ò› Ñ‚Ñ–Ð»Ñ–', 'liter_10': 'Ó˜Ð´ÐµÐ±Ð¸ÐµÑ‚', 'rus_lang_10': 'ÐžÑ€Ñ‹Ñ Ñ‚Ñ–Ð»Ñ–',
    'eng_lang_10': 'ÐÒ“Ñ‹Ð»ÑˆÑ‹Ð½ Ñ‚Ñ–Ð»Ñ–', 'math_10': 'ÐœÐ°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐ°', 'comps_10': 'Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ÐºÐ°',
    'kaz_hist_10': 'ÒšÐ°Ð·Ð°Ò›ÑÑ‚Ð°Ð½ Ñ‚Ð°Ñ€Ð¸Ñ…Ñ‹', 'art_10': 'Ð‘ÐµÐ¹Ð½ÐµÐ»ÐµÑƒ Ó©Ð½ÐµÑ€Ñ–', 'pe_10': 'Ð”ÐµÐ½Ðµ ÑˆÑ‹Ð½Ñ‹Ò›Ñ‚Ñ‹Ñ€Ñƒ',
    'geography_10': 'Ð“ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ', 'biology_10': 'Ð‘Ð¸Ð¾Ð»Ð¾Ð³Ð¸Ñ', 'chemistry_10': 'Ð¥Ð¸Ð¼Ð¸Ñ',
    'physics_10': 'Ð¤Ð¸Ð·Ð¸ÐºÐ°', 'world_hist_10': 'Ð”Ò¯Ð½Ð¸ÐµÐ¶Ò¯Ð·Ñ– Ñ‚Ð°Ñ€Ð¸Ñ…Ñ‹'
}

# QUESTIONS / EXPANDER TEXTS (previously lang_dict)
lang_meta = {
    "ru": {
        "expander": "Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð·Ð° {grade} ÐºÐ»Ð°ÑÑ:",
        "most_suitable": "ÐÐ°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ Ñ‚Ð¸Ð¿Ñ‹:",
        "probability": "Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ",
        "type": "Ð¢Ð¸Ð¿",
        "questions": [
            "**1. ÐšÐ°ÐºÐ¸Ðµ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¸ Ð²Ð°Ñ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÑŽÑ‚ Ð½Ð° Ð´Ð°Ð½Ð½Ñ‹Ð¹ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚?**",
            "**2. ÐšÐ°ÐºÐ¸Ðµ Ð²Ð¸Ð´Ñ‹ Ð´ÐµÑÑ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð²Ð°Ð¼ Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð½Ðµ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹?**",
            "**3. Ð‘ÐµÐ· ÑƒÑ‡ÐµÑ‚Ð° Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ñ… Ð°ÑÐ¿ÐµÐºÑ‚Ð¾Ð², ÐºÐ°ÐºÐ¸Ðµ Ð²Ð¸Ð´Ñ‹ Ð´ÐµÑÑ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¸ Ð²Ð°Ð¼ Ð½Ñ€Ð°Ð²ÑÑ‚ÑÑ?**",
            "**4. ÐŸÐµÑ€ÐµÑ‡Ð¸ÑÐ»Ð¸Ñ‚Ðµ ÑÐ²Ð¾Ð¸ Ñ…Ð¾Ð±Ð±Ð¸ Ð¸ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑ‹:**",
            "**5. ÐÐ°Ð·Ð¾Ð²Ð¸Ñ‚Ðµ Ñ€Ð¾Ð»ÐµÐ²Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸, Ñ‡ÑŒÐ¸ Ð¾Ð±Ñ€Ð°Ð·Ñ‹ Ð¶Ð¸Ð·Ð½Ð¸ Ð¸ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ Ð²Ð°Ñ Ð²Ð´Ð¾Ñ…Ð½Ð¾Ð²Ð»ÑÑŽÑ‚.**",
            "**6. ÐšÐ°ÐºÐ¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¿Ñ€Ð¸Ð´Ð°ÑŽÑ‚ Ð²Ð°Ð¼ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸?**",
            "**7. ÐšÐ°ÐºÐ¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð²Ð°Ñ ÑƒÑ‚Ð¾Ð¼Ð»ÑÑŽÑ‚?**"
        ]
    },
    "en": {
        "expander": "Enter grades for grade {grade}:",
        "most_suitable": "Most suitable types:",
        "probability": "Probability",
        "type": "Type",
        "questions": [
            "**1. Which professions are you currently interested in?**",
            "**2. Which activities are you definitely not interested in?**",
            "**3. Regardless of finances, which activities or professions do you enjoy?**",
            "**4. List your hobbies and interests:**",
            "**5. Name role models whose lifestyles and achievements inspire you.**",
            "**6. Which tasks give you energy?**",
            "**7. Which tasks drain your energy?**"
        ]
    },
    "kz": {
        "expander": "{grade}-ÑÑ‹Ð½Ñ‹Ð¿ Ð±Ð°Ò“Ð°Ð»Ð°Ñ€Ñ‹Ð½ ÐµÐ½Ð³Ñ–Ð·Ñ–Ò£Ñ–Ð·:",
        "most_suitable": "Ð•Ò£ Ò›Ð¾Ð»Ð°Ð¹Ð»Ñ‹ Ñ‚Ð¸Ð¿Ñ‚ÐµÑ€:",
        "probability": "Ð«Ò›Ñ‚Ð¸Ð¼Ð°Ð»Ð´Ñ‹Ò›",
        "type": "Ð¢Ò¯Ñ€Ñ–",
        "questions": [
            "**1. ÒšÐ°Ð·Ñ–Ñ€ ÑÑ–Ð·Ð´Ñ– Ò›Ð°Ð½Ð´Ð°Ð¹ Ð¼Ð°Ð¼Ð°Ð½Ð´Ñ‹Ò›Ñ‚Ð°Ñ€ Ò›Ñ‹Ð·Ñ‹Ò›Ñ‚Ñ‹Ñ€Ð°Ð´Ñ‹?**",
            "**2. Ð¡Ñ–Ð·Ð³Ðµ Ð¼Ò¯Ð»Ð´ÐµÐ¼ Ò›Ñ‹Ð·Ñ‹Ò› ÐµÐ¼ÐµÑ Ñ–Ñ-Ó™Ñ€ÐµÐºÐµÑ‚Ñ‚ÐµÑ€ Ò›Ð°Ð½Ð´Ð°Ð¹?**",
            "**3. ÒšÐ°Ñ€Ð¶Ñ‹Ð»Ñ‹Ò› Ð°ÑÐ¿ÐµÐºÑ‚Ñ–Ð»ÐµÑ€Ð´Ñ– ÐµÑÐµÐ¿Ñ‚ÐµÐ¼ÐµÐ³ÐµÐ½Ð´Ðµ, Ò›Ð°Ð½Ð´Ð°Ð¹ Ñ–Ñ-Ó™Ñ€ÐµÐºÐµÑ‚Ñ‚ÐµÑ€ Ð½ÐµÐ¼ÐµÑÐµ Ð¼Ð°Ð¼Ð°Ð½Ð´Ñ‹Ò›Ñ‚Ð°Ñ€ Ò±Ð½Ð°Ð¹Ð´Ñ‹?**",
            "**4. Ð¥Ð¾Ð±Ð±Ð¸Ñ–Ò£Ñ–Ð· Ð±ÐµÐ½ Ò›Ñ‹Ð·Ñ‹Ò“ÑƒÑˆÑ‹Ð»Ñ‹Ò›Ñ‚Ð°Ñ€Ñ‹Ò£Ñ‹Ð·Ð´Ñ‹ Ð¶Ð°Ð·Ñ‹Ò£Ñ‹Ð·:**",
            "**5. Ð¡Ñ–Ð·Ð´Ñ– Ó©Ð¼Ñ–Ñ€ ÑÐ°Ð»Ñ‚Ñ‹ Ð¼ÐµÐ½ Ð¶ÐµÑ‚Ñ–ÑÑ‚Ñ–ÐºÑ‚ÐµÑ€Ñ–Ð¼ÐµÐ½ ÑˆÐ°Ð±Ñ‹Ñ‚Ñ‚Ð°Ð½Ð´Ñ‹Ñ€Ð°Ñ‚Ñ‹Ð½ Ñ‚Ò±Ð»Ò“Ð°Ð»Ð°Ñ€Ð´Ñ‹ Ð°Ñ‚Ð°Ò£Ñ‹Ð·.**",
            "**6. Ð¡Ñ–Ð·Ð³Ðµ ÐºÒ¯Ñˆ-Ò›ÑƒÐ°Ñ‚ Ð±ÐµÑ€ÐµÑ‚Ñ–Ð½ Ñ‚Ð°Ð¿ÑÑ‹Ñ€Ð¼Ð°Ð»Ð°Ñ€ Ò›Ð°Ð½Ð´Ð°Ð¹?**",
            "**7. Ð¡Ñ–Ð·Ð´Ñ– ÑˆÐ°Ñ€ÑˆÐ°Ñ‚Ð°Ñ‚Ñ‹Ð½ Ñ‚Ð°Ð¿ÑÑ‹Ñ€Ð¼Ð°Ð»Ð°Ñ€ Ò›Ð°Ð½Ð´Ð°Ð¹?**"
        ]
    }
}

# UI translations
translations = {
    "en": {
        "header": "AI-powered program for school career guidance",
        "tab1": "School grades",
        "tab2": "Open questions",
        "tab3": "AI career assistant",
        "choose_type": "Choose your motivational type:",
        "get_result": "Get result",
        "most_suitable": "Most suitable types:",
        "get_answer": "Get answer",
        "ai_response": "AI Response:",
        "advisor": "ðŸŽ“ Career Guidance AI Assistant",
        "student_question": "Enter your question:",
        "rag_toggle": "Enable RAG",
        "get_advice": "Get advice",
        "base_model": "ðŸ’¡ Base model",
        "rag_model": "ðŸ“š Model with RAG",
        "expander": "Grades for {grade} grade",
        "questions": lang_meta["en"]["questions"]
    },
    "ru": {
        "header": "Ð˜Ð˜ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð° Ð´Ð»Ñ ÑˆÐºÐ¾Ð»ÑŒÐ½Ð¾Ð¹ Ð¿Ñ€Ð¾Ñ„Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸",
        "tab1": "Ð¨ÐºÐ¾Ð»ÑŒÐ½Ñ‹Ðµ Ð¾Ñ†ÐµÐ½ÐºÐ¸",
        "tab2": "ÐžÑ‚ÐºÑ€Ñ‹Ñ‚Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹",
        "tab3": "AI Ð¿Ñ€Ð¾Ñ„Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ‚Ð¾Ñ€",
        "choose_type": "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÐ²Ð¾Ð¹ Ð¼Ð¾Ñ‚Ð¸Ð²Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹ Ñ‚Ð¸Ð¿:",
        "get_result": "ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚",
        "most_suitable": "ÐÐ°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ Ñ‚Ð¸Ð¿Ñ‹:",
        "get_answer": "ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚",
        "ai_response": "ÐžÑ‚Ð²ÐµÑ‚ Ð˜Ð˜:",
        "advisor": "ðŸŽ“ ÐŸÑ€Ð¾Ñ„Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹ AI Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚",
        "student_question": "Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð²Ð°Ñˆ Ð²Ð¾Ð¿Ñ€Ð¾Ñ:",
        "rag_toggle": "Ð’ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ RAG",
        "get_advice": "ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐ¾Ð²ÐµÑ‚",
        "base_model": "ðŸ’¡ Ð‘Ð°Ð·Ð¾Ð²Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ",
        "rag_model": "ðŸ“š ÐœÐ¾Ð´ÐµÐ»ÑŒ Ñ RAG",
        "expander": "ÐžÑ†ÐµÐ½ÐºÐ¸ Ð·Ð° {grade} ÐºÐ»Ð°ÑÑ",
        "questions": lang_meta["ru"]["questions"]
    },
    "kz": {
        "header": "ÐœÐµÐºÑ‚ÐµÐ¿Ñ‚Ñ–Ðº ÐºÓ™ÑÑ–Ð±Ð¸ Ð±Ð°Ò“Ð´Ð°Ñ€ Ð±ÐµÑ€ÑƒÐ³Ðµ Ð°Ñ€Ð½Ð°Ð»Ò“Ð°Ð½ Ð–Ð˜ Ð±Ð°Ò“Ð´Ð°Ñ€Ð»Ð°Ð¼Ð°",
        "tab1": "ÐœÐµÐºÑ‚ÐµÐ¿ Ð±Ð°Ò“Ð°Ð»Ð°Ñ€Ñ‹",
        "tab2": "ÐÑˆÑ‹Ò› ÑÒ±Ñ€Ð°Ò›Ñ‚Ð°Ñ€",
        "tab3": "Ð–Ð˜ ÐºÓ™ÑÑ–Ð±Ð¸ Ð±Ð°Ò“Ð´Ð°Ñ€ÑˆÑ‹",
        "choose_type": "Ó¨Ð· Ð¼Ð¾Ñ‚Ð¸Ð²Ð°Ñ†Ð¸ÑÐ»Ñ‹Ò› Ñ‚Ð¸Ð¿Ñ–Ò£Ñ–Ð·Ð´Ñ– Ñ‚Ð°Ò£Ð´Ð°Ò£Ñ‹Ð·:",
        "get_result": "ÐÓ™Ñ‚Ð¸Ð¶Ðµ Ð°Ð»Ñƒ",
        "most_suitable": "Ð•Ò£ Ò›Ð¾Ð»Ð°Ð¹Ð»Ñ‹ Ñ‚Ð¸Ð¿Ñ‚ÐµÑ€:",
        "get_answer": "Ð–Ð°ÑƒÐ°Ð¿ Ð°Ð»Ñƒ",
        "ai_response": "Ð–Ð˜ Ð¶Ð°ÑƒÐ°Ð±Ñ‹:",
        "advisor": "ðŸŽ“ ÐšÓ™ÑÑ–Ð±Ð¸ Ð±Ð°Ò“Ð´Ð°Ñ€ Ð±ÐµÑ€ÐµÑ‚Ñ–Ð½ Ð–Ð˜ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ñ–",
        "student_question": "Ð¡Ò±Ñ€Ð°Ò“Ñ‹Ò£Ñ‹Ð·Ð´Ñ‹ ÐµÐ½Ð³Ñ–Ð·Ñ–Ò£Ñ–Ð·:",
        "rag_toggle": "RAG Ò›Ð¾ÑÑƒ",
        "get_advice": "ÐšÐµÒ£ÐµÑ Ð°Ð»Ñƒ",
        "base_model": "ðŸ’¡ ÐÐµÐ³Ñ–Ð·Ð³Ñ– Ð¼Ð¾Ð´ÐµÐ»ÑŒ",
        "rag_model": "ðŸ“š RAG Ð¼Ð¾Ð´ÐµÐ»Ñ–",
        "expander": "{grade} ÑÑ‹Ð½Ñ‹Ð¿ Ð±Ð°Ò“Ð°Ð»Ð°Ñ€Ñ‹",
        "questions": lang_meta["kz"]["questions"]
    }
}

# ==========================
#  HELPERS / MODEL / RAG
# ==========================
def create_expander(class_label, cols, lang_meta_dict, column_names_dict, input_values):
    """Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ñ‚ expander Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½Ð¾Ðº; input_values - dict ÐºÑƒÐ´Ð° Ð¿Ð¸ÑˆÐµÐ¼."""
    with st.expander(lang_meta_dict["expander"].format(grade=class_label)):
        for col in cols:
            input_values[col] = st.number_input(
                column_names_dict[col], min_value=2, max_value=5, step=1, value=5, key=col
            )

def save_to_dataframe(selected_checkboxes, input_values):
    data = {**selected_checkboxes, **input_values}
    for key in checkbox_columns:
        data[key] = int(data.get(key, False))
    df = pd.DataFrame([data], columns=inp_col_names)
    return df

def apply_model(model_path, input_df):
    """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÐµÐ¹.
    ÐŸÐ¾Ð´ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²ÐºÐ°: ÐµÑÐ»Ð¸ model.predict_proba Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¸Ð»Ð¸ array."""
    model = joblib.load(model_path)
    probabilities = model.predict_proba(input_df)

    # handle case when predict_proba returns list of arrays (OneVsRest style)
    if isinstance(probabilities, list):
        # each element is (n_samples, 2) â€” take [:,1]
        probs = np.vstack([arr[:, 1] for arr in probabilities]).T  # (n_samples, n_classes)
    else:
        probs = np.array(probabilities)  # (n_samples, n_classes)

    # build dict class_i -> column
    probability_dict = {f'class_{i}': probs[:, i] for i in range(probs.shape[1])}
    return pd.DataFrame(probability_dict)

def adjust_probabilities(probabilities, thresholds):
    return {key: min(100, (val / thresholds.get(key, 1e-9)) * 100) for key, val in probabilities.items()}

def display_results(df, lang_meta_dict, type_columns_dict):
    results = {key: df[key].values[0] for key in df.columns}
    adjusted = adjust_probabilities(results, thresholds)
    # selected types where adjusted >= 100
    selected_types = [type_columns_dict.get(k, k) for k, v in adjusted.items() if v >= 100]

    st.write(f"**{lang_meta_dict['most_suitable']}**")
    for t_name in selected_types:
        st.write(f"- {t_name}")

    # DataFrame for chart: use labels from lang_meta_dict["type"] and ["probability"]
    chart_data = pd.DataFrame({
        lang_meta_dict["type"]: [type_columns_dict.get(k, k) for k in adjusted.keys()],
        lang_meta_dict["probability"]: list(adjusted.values())
    })
    st.dataframe(chart_data, use_container_width=True)
    st.bar_chart(chart_data.set_index(lang_meta_dict["type"]))

def get_ai_response(answers):
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {st.secrets['OPENAI_API_KEY']}", "Content-Type": "application/json"}
    data = {
        "model": "ft:gpt-4o-2024-08-06:personal::An4sVvnb",
        "messages": [
            {
                "role": "system",
                "content": (
                    "Assistant is an expert in career guidance. Assistant should answer in the same language "
                    "as the one in which the user writes answers (could be russian, kazakh, english). "
                    "User answers the following questions: "
                    "1. ÐšÐ°ÐºÐ¸Ðµ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¸ Ð²Ð°Ñ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÑŽÑ‚ Ð½Ð° Ð´Ð°Ð½Ð½Ñ‹Ð¹ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚? "
                    "2. ÐšÐ°ÐºÐ¸Ðµ Ð²Ð¸Ð´Ñ‹ Ð´ÐµÑÑ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð²Ð°Ð¼ Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð½Ðµ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹? "
                    "3. Ð‘ÐµÐ· ÑƒÑ‡ÐµÑ‚Ð° Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ñ… Ð°ÑÐ¿ÐµÐºÑ‚Ð¾Ð², ÐºÐ°ÐºÐ¸Ðµ Ð²Ð¸Ð´Ñ‹ Ð´ÐµÑÑ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¸ Ð²Ð°Ð¼ Ð½Ñ€Ð°Ð²ÑÑ‚ÑÑ? "
                    "4. ÐŸÐµÑ€ÐµÑ‡Ð¸ÑÐ»Ð¸Ñ‚Ðµ ÑÐ²Ð¾Ð¸ Ñ…Ð¾Ð±Ð±Ð¸ Ð¸ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑ‹: "
                    "5. ÐÐ°Ð·Ð¾Ð²Ð¸Ñ‚Ðµ Ñ€Ð¾Ð»ÐµÐ²Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸, Ñ‡ÐµÐ¹ Ð¾Ð±Ñ€Ð°Ð· Ð¶Ð¸Ð·Ð½Ð¸ Ð¸ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ Ð²Ð°Ñ Ð²Ð´Ð¾Ñ…Ð½Ð¾Ð²Ð»ÑÑŽÑ‚. "
                    "6. ÐšÐ°ÐºÐ¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¿Ñ€Ð¸Ð´Ð°ÑŽÑ‚ Ð²Ð°Ð¼ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸? "
                    "7. ÐšÐ°ÐºÐ¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð²Ð°Ñ ÑƒÑ‚Ð¾Ð¼Ð»ÑÑŽÑ‚?"
                )
            },
            {
                "role": "user",
                "content": f"1. {answers[0]} 2. {answers[1]} 3. {answers[2]} 4. {answers[3]} 5. {answers[4]} 6. {answers[5]} 7. {answers[6]}"
            }
        ],
        "max_tokens": 500
    }

    response = requests.post(url, headers=headers, json=data)
    response.raise_for_status()
    return response.json()["choices"][0]["message"]["content"]

@st.cache_data(show_spinner="Loading...")
def load_jsonl_files(folder_path):
    records = []
    if not os.path.exists(folder_path):
        return records
    for filename in os.listdir(folder_path):
        if filename.endswith(".jsonl"):
            with open(os.path.join(folder_path, filename), "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        records.append(json.loads(line))
                    except json.JSONDecodeError:
                        pass
    return records

def login_hf():
    if not os.environ.get("HF_TOKEN"):
        login(token=st.secrets["HF_TOKEN"])

@st.cache_resource
def load_annoy_index(rag_data):
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
    texts = [item.get("text", "") for item in rag_data]
    index = AnnoyIndex(384, 'angular')
    if os.path.exists("index.ann"):
        index.load("index.ann")
    return embedder, index, texts

def generate_rag_career_advice(question: str, embedder, annoy_index, texts: list, k: int = 5) -> str:
    query_embedding = embedder.encode([question], convert_to_numpy=True)
    indices = annoy_index.get_nns_by_vector(query_embedding[0], k, include_distances=False)
    context_docs = [texts[i] for i in indices if i < len(texts)]
    context = "\n\n".join(context_docs)
    messages = [ {"role": "system", "content": f""" You are a career advisor for high school students. You have access to relevant background knowledge about career paths, student preferences, and educational strategies, shown below. Context: {context} Your only task is to select 3 career paths that are the best possible match for the student's stated interests, strengths, and dislikes. Strict instructions: - Base your suggestions strictly on the studentâ€™s message. Do not invent or assume anything not mentioned. - Recommend only career paths that clearly align with what the student enjoys and is good at, and that avoid what they dislike or find difficult. - For each suggested path, explain in 3-4 sentences why it fits this student specifically. - Do not give general advice or list unrelated options "just in case." - Keep the total response under 350 words. Be focused and relevant. If student asks other questions, answer them directly (still use the background context) and do not generate career paths if not asked. """}, {"role": "user", "content": question} ]
    client = InferenceClient(provider="auto", api_key=st.secrets["HF_TOKEN"])
    response = client.chat.completions.create(
        model="meta-llama/Meta-Llama-3-8B-Instruct",
        messages=messages,
        max_tokens=500,
        temperature=0.7
    )
    answer = response.choices[0].message.content
    if not answer.endswith("."):
        last_period = answer.rfind(".")
        if last_period != -1:
            answer = answer[:last_period + 1]
        else:
            answer = answer.strip()
    return answer

# ==========================
#  PDF SAVE HELPERS
# ==========================
def save_tab1_results_to_pdf(results_df, lang):
    buffer = io.BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4
    c.setFont("Helvetica-Bold", 14)
    c.drawString(50, height - 50, {
        "ru": "Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ñ€Ð¾Ñ„Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð¾Ð³Ð¾ Ñ‚ÐµÑÑ‚Ð° (Ð¾Ñ†ÐµÐ½ÐºÐ¸)",
        "en": "Career guidance results (grades)",
        "kz": "ÐšÓ™ÑÑ–Ð±Ð¸ Ð±Ð°Ò“Ð´Ð°Ñ€ Ð½Ó™Ñ‚Ð¸Ð¶ÐµÐ»ÐµÑ€Ñ– (Ð±Ð°Ò“Ð°Ð»Ð°Ñ€)"
    }[lang])
    c.setFont("Helvetica", 12)
    y = height - 100
    for idx, row in results_df.iterrows():
        for col, val in row.items():
            c.drawString(50, y, f"{col}: {val}")
            y -= 20
            if y < 80:
                c.showPage()
                y = height - 50
    c.save()
    buffer.seek(0)
    return buffer

def save_tab2_results_to_pdf(questions, answers, ai_response, lang):
    buffer = io.BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4
    c.setFont("Helvetica-Bold", 14)
    c.drawString(50, height - 50, {
        "ru": "ÐžÑ‚ÐºÑ€Ñ‹Ñ‚Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð· Ð˜Ð˜",
        "en": "Open questions and AI analysis",
        "kz": "ÐÑˆÑ‹Ò› ÑÒ±Ñ€Ð°Ò›Ñ‚Ð°Ñ€ Ð¼ÐµÐ½ Ð–Ð˜ Ñ‚Ð°Ð»Ð´Ð°ÑƒÑ‹"
    }[lang])
    c.setFont("Helvetica", 12)
    y = height - 100
    for q, a in zip(questions, answers):
        c.drawString(50, y, f"Q: {q}")
        y -= 18
        c.drawString(70, y, f"A: {a}")
        y -= 28
        if y < 80:
            c.showPage()
            y = height - 50
    c.setFont("Helvetica-Bold", 12)
    c.drawString(50, y, {"ru": "ÐžÑ‚Ð²ÐµÑ‚ Ð˜Ð˜:", "en": "AI Response:", "kz": "Ð–Ð˜ Ð¶Ð°ÑƒÐ°Ð±Ñ‹:"}[lang])
    y -= 18
    c.setFont("Helvetica", 12)
    for line in ai_response.splitlines():
        c.drawString(50, y, line)
        y -= 16
        if y < 80:
            c.showPage()
            y = height - 50
    c.save()
    buffer.seek(0)
    return buffer

def save_tab3_results_to_pdf(question, rag_response, lang):
    buffer = io.BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4
    c.setFont("Helvetica-Bold", 14)
    c.drawString(50, height - 50, {
        "ru": "AI Ð¿Ñ€Ð¾Ñ„Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ (RAG Ð¼Ð¾Ð´ÐµÐ»ÑŒ)",
        "en": "AI career guidance (RAG model)",
        "kz": "Ð–Ð˜ ÐºÓ™ÑÑ–Ð±Ð¸ Ð±Ð°Ò“Ð´Ð°Ñ€ (RAG Ð¼Ð¾Ð´ÐµÐ»Ñ–)"
    }[lang])
    c.setFont("Helvetica", 12)
    y = height - 100
    c.drawString(50, y, {"ru": "Ð’Ð¾Ð¿Ñ€Ð¾Ñ ÑƒÑ‡ÐµÐ½Ð¸ÐºÐ°:", "en": "Student's question:", "kz": "ÐžÒ›ÑƒÑˆÑ‹ ÑÒ±Ñ€Ð°Ò“Ñ‹:"}[lang])
    y -= 18
    for line in question.splitlines():
        c.drawString(70, y, line)
        y -= 16
        if y < 80:
            c.showPage()
            y = height - 50
    y -= 10
    c.setFont("Helvetica-Bold", 12)
    c.drawString(50, y, {"ru": "ÐžÑ‚Ð²ÐµÑ‚ RAG Ð¼Ð¾Ð´ÐµÐ»Ð¸:", "en": "RAG model response:", "kz": "RAG Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¶Ð°ÑƒÐ°Ð±Ñ‹:"}[lang])
    y -= 18
    c.setFont("Helvetica", 12)
    for line in rag_response.splitlines():
        c.drawString(50, y, line)
        y -= 16
        if y < 80:
            c.showPage()
            y = height - 50
    c.save()
    buffer.seek(0)
    return buffer

# ==========================
#  INTERFACE
# ==========================
# ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ (label â†’ value)
lang_options = {"KZ": "kz", "EN": "en", "RU": "ru"}

# ÑÐµÐ»ÐµÐºÑ‚Ð¾Ñ€ ÑÐ¿Ñ€Ð°Ð²Ð° ÑÐ²ÐµÑ€Ñ…Ñƒ: ÑÐ¾Ð·Ð´Ð°Ñ‘Ð¼ 3 ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸, Ð¿Ñ€Ð°Ð²Ð°Ñ ÑƒÐ·ÐºÐ°Ñ
col1, col2, col3 = st.columns([8, 1, 2])
with col3:
    lang_label = st.selectbox(" ", options=list(lang_options.keys()), index=0)

# Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ lang Ð² Ð½Ð¸Ð¶Ð½ÐµÐ¼ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ðµ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² session_state
lang = lang_options[lang_label]
st.session_state["lang"] = lang  # Ð²ÑÐµÐ³Ð´Ð° Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ â€” Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾

# t = UI translations, ld = questions/expander strings
t = translations[lang]
ld = lang_meta[lang]

# ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ð¹ Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚Ð¾Ð² Ð¿Ð¾ ÑÐ·Ñ‹ÐºÑƒ
column_names_dicts = {"ru": column_names_dict_ru, "en": column_names_dict_en, "kz": column_names_dict_kz}
current_column_names = column_names_dicts[lang]

# Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ RAG Ð¸ Ð¸Ð½Ð´ÐµÐºÑ (ÐºÑÑˆÐ¸Ñ€ÑƒÑŽÑ‚ÑÑ)
input_values = {}
rag_data = load_jsonl_files("./jsonl datafiles")
login_hf()
embedder, annoy_index, texts = load_annoy_index(rag_data)

st.header(t["header"])
tabs = st.tabs([t["tab1"], t["tab2"], t["tab3"]])

# ------------------------
# TAB 1 - Grades
# ------------------------
with tabs[0]:
    with st.form("grades_form"):
        st.write(f"**{t['choose_type']}**")
        selected_checkboxes = {
            col: st.checkbox(current_column_names[col]) for col in checkbox_columns
        }
        for grade in [7, 8, 9, 10]:
            create_expander(
                grade,
                [c for c in inp_col_names if c.endswith(f"_{grade}")],
                ld,
                current_column_names,
                input_values
            )
        submit_tab1 = st.form_submit_button(t["get_result"])

    if submit_tab1:
        df = save_to_dataframe(selected_checkboxes, input_values)
        try:
            result_df = apply_model("random_forest_model.pkl", df)
        except Exception as e:
            st.error(f"Error applying model: {e}")
            result_df = None
        st.session_state["tab1_results"] = result_df

    if "tab1_results" in st.session_state and st.session_state["tab1_results"] is not None:
        # pick right type_columns dict
        if lang == "ru":
            type_columns_dict = type_columns_ru
        elif lang == "kz":
            type_columns_dict = type_columns_kz
        else:
            type_columns_dict = type_columns_en

        display_results(st.session_state["tab1_results"], ld, type_columns_dict)

        # description block (localized)
        if lang == "ru":
            st.title("Ð¢Ð¸Ð¿Ñ‹ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð´ÐµÑÑ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸")
            st.markdown("""
**1. Ð§Ð•Ð›ÐžÐ’Ð•Ðš-Ð–Ð˜Ð’ÐÐ¯ ÐŸÐ Ð˜Ð ÐžÐ”Ð (ÐŸ).**  
ÐŸÑ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¸Ñ‚ÐµÐ»Ð¸ ÑÑ‚Ð¾Ð³Ð¾ Ñ‚Ð¸Ð¿Ð° Ð¸Ð¼ÐµÑŽÑ‚ Ð´ÐµÐ»Ð¾ Ñ Ñ€Ð°ÑÑ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð¸ Ð¶Ð¸Ð²Ñ‹Ð¼Ð¸ Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð¼Ð°Ð¼Ð¸, Ð¼Ð¸ÐºÑ€Ð¾Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð¼Ð°Ð¼Ð¸ Ð¸ ÑƒÑÐ»Ð¾Ð²Ð¸ÑÐ¼Ð¸ Ð¸Ñ… ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ñ  
*(Ð°Ð³Ñ€Ð¾Ð½Ð¾Ð¼, Ð²ÐµÑ‚Ð²Ñ€Ð°Ñ‡, Ð¿Ð¾Ð»ÐµÐ²Ð¾Ð´, Ð¶Ð¸Ð²Ð¾Ñ‚Ð½Ð¾Ð²Ð¾Ð´, ÐºÐ¸Ð½Ð¾Ð»Ð¾Ð³, Ñ„ÐµÑ€Ð¼ÐµÑ€, Ð³ÐµÐ¾Ð»Ð¾Ð³)*.

---

**2. Ð§Ð•Ð›ÐžÐ’Ð•Ðš-Ð¢Ð•Ð¥ÐÐ˜ÐšÐ Ð˜ ÐÐ•Ð–Ð˜Ð’ÐÐ¯ ÐŸÐ Ð˜Ð ÐžÐ”Ð (Ð¢).**  
Ð Ð°Ð±Ð¾Ñ‚Ð½Ð¸ÐºÐ¸ Ð¸Ð¼ÐµÑŽÑ‚ Ð´ÐµÐ»Ð¾ Ñ Ð½ÐµÐ¶Ð¸Ð²Ñ‹Ð¼Ð¸ Ð¸ Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼Ð¸ Ð¾Ð±ÑŠÐµÐºÑ‚Ð°Ð¼Ð¸ Ñ‚Ñ€ÑƒÐ´Ð°  
*(ÑÐ»ÐµÑÐ°Ñ€ÑŒ, Ð°Ð²Ñ‚Ð¾Ð¼ÐµÑ…Ð°Ð½Ð¸Ðº, Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ, Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€, Ð¼Ð¾Ñ‚Ð¾Ñ€Ð¸ÑÑ‚, Ð¿Ð»Ð¾Ñ‚Ð½Ð¸Ðº, ÑˆÑ‚ÑƒÐºÐ°Ñ‚ÑƒÑ€, ÑÐ²Ð°Ñ€Ñ‰Ð¸Ðº, ÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ‚Ð¾Ñ€, ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÐµÑ€, Ñ„Ð¸Ð·Ð¸Ðº, Ñ…Ð¸Ð¼Ð¸Ðº)*.

---

**3. Ð§Ð•Ð›ÐžÐ’Ð•Ðš-Ð§Ð•Ð›ÐžÐ’Ð•Ðš (Ð§).**  
ÐŸÑ€ÐµÐ´Ð¼ÐµÑ‚Ð¾Ð¼ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ°, Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð¸Ñ, Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ, Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð·Ð´ÐµÑÑŒ ÑÐ²Ð»ÑÑŽÑ‚ÑÑ ÑÐ¾Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹, ÑÐ¾Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð°, Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð½Ð°ÑÐµÐ»ÐµÐ½Ð¸Ñ, Ð»ÑŽÐ´Ð¸ Ñ€Ð°Ð·Ð½Ð¾Ð³Ð¾ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚Ð°  
*(ÑƒÑ‡Ð¸Ñ‚ÐµÐ»ÑŒ, Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€, Ð²Ñ€Ð°Ñ‡, ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²Ð¾Ð¹ Ð°Ð³ÐµÐ½Ñ‚, Ð²Ð¾ÑÐ¿Ð¸Ñ‚Ð°Ñ‚ÐµÐ»ÑŒ, Ð½ÑÐ½Ñ, Ð¿Ñ€Ð¾Ð´Ð°Ð²ÐµÑ†, ÑÐ¾Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð°Ð±Ð¾Ñ‚Ð½Ð¸Ðº, Ð¼Ð°ÑÑÐ°Ð¶Ð¸ÑÑ‚, Ð¿ÑÐ¸Ñ…Ð¾Ð»Ð¾Ð³)*.

---

**4. Ð§Ð•Ð›ÐžÐ’Ð•Ðš-Ð—ÐÐÐšÐžÐ’ÐÐ¯ Ð¡Ð˜Ð¡Ð¢Ð•ÐœÐ (Ð—).**  
Ð•ÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ Ð¸ Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ ÑÐ·Ñ‹ÐºÐ¸, ÑƒÑÐ»Ð¾Ð²Ð½Ñ‹Ðµ Ð·Ð½Ð°ÐºÐ¸, ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹, Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ñ‹ â€” Ð²Ð¾Ñ‚ Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚Ð½Ñ‹Ðµ Ð¼Ð¸Ñ€Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð·Ð°Ð½Ð¸Ð¼Ð°ÑŽÑ‚ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¸Ñ‚ÐµÐ»ÐµÐ¹ ÑÑ‚Ð¾Ð³Ð¾ Ñ‚Ð¸Ð¿Ð°  
*(Ð±ÑƒÑ…Ð³Ð°Ð»Ñ‚ÐµÑ€, Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸ÑÑ‚, Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€ ÐŸÐš, Ñ€Ð°Ð´Ð¸Ð¾Ð¼Ð¾Ð½Ñ‚Ð°Ð¶Ð½Ð¸Ðº, ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸ÑÑ‚, Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½Ð¸ÑÑ‚, Ð¼Ð°ÑˆÐ¸Ð½Ð¸ÑÑ‚ÐºÐ°, Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ñ‡Ð¸Ðº, ÐºÐ°ÑÑÐ¸Ñ€)*.

---

**5. Ð§Ð•Ð›ÐžÐ’Ð•Ðš-Ð¥Ð£Ð”ÐžÐ–Ð•Ð¡Ð¢Ð’Ð•ÐÐÐ«Ð™ ÐžÐ‘Ð ÐÐ— (Ð¥).**  
Ð¯Ð²Ð»ÐµÐ½Ð¸Ñ, Ñ„Ð°ÐºÑ‚Ñ‹ Ñ…ÑƒÐ´Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ â€” Ð²Ð¾Ñ‚ Ñ‡Ñ‚Ð¾ Ð·Ð°Ð½Ð¸Ð¼Ð°ÐµÑ‚ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¸Ñ‚ÐµÐ»ÐµÐ¹ ÑÑ‚Ð¾Ð³Ð¾ Ñ‚Ð¸Ð¿Ð°  
*(Ð°Ñ€Ñ‚Ð¸ÑÑ‚, Ð´Ð¸Ñ€Ð¸Ð¶ÐµÑ€, Ñ…ÑƒÐ´Ð¾Ð¶Ð½Ð¸Ðº, Ð¼Ð°Ð»ÑÑ€, Ð¿Ð¾Ñ€Ñ‚Ð½Ð¾Ð¹, Ð¿Ð¾Ð²Ð°Ñ€, Ð¿Ð°Ñ€Ð¸ÐºÐ¼Ð°Ñ…ÐµÑ€, Ð¼ÑƒÐ·Ñ‹ÐºÐ°Ð½Ñ‚, Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚Ð¾Ñ€)*.

---

**6. Ð§Ð•Ð›ÐžÐ’Ð•Ðš-Ð‘Ð˜Ð—ÐÐ•Ð¡ (Ð‘).**  
Ð’Ñ‹Ð´ÐµÐ»ÐµÐ½ Ð² Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ Ð² ÑÐ²ÑÐ·Ð¸ Ñ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð½Ð¾ÑÑ‚ÑŒÑŽ Ñ€Ñ‹Ð½ÐºÐ° Ñ‚Ñ€ÑƒÐ´Ð°.  
Ð¡ÑŽÐ´Ð° Ð¾Ñ‚Ð½Ð¾ÑÑÑ‚ÑÑ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸: *Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€Ñ‹, Ð±Ð¸Ñ€Ð¶ÐµÐ²Ñ‹Ðµ Ð¼Ð°ÐºÐ»ÐµÑ€Ñ‹, Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ñ‹, Ð±Ñ€Ð¾ÐºÐµÑ€Ñ‹, Ð´Ð¸Ð»ÐµÑ€Ñ‹ Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¸, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ Ñ ÐºÐ¾Ð¼Ð¼ÐµÑ€Ñ‡ÐµÑÐºÐ¾Ð¹ Ð´ÐµÑÑ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒÑŽ*.
""")

        elif lang == "en":
            st.title("Types of professional activities")
            st.markdown("""
**1. HUMANâ€“NATURE (N).**  
Work with plants, animals, microorganisms, and their living conditions  
*(agronomist, veterinarian, farmer, dog handler, geologist)*.

---

**2. HUMANâ€“TECHNOLOGY (T).**  
Work with inanimate objects and technical systems  
*(mechanic, driver, engineer, carpenter, welder, constructor, physicist, chemist)*.

---

**3. HUMANâ€“HUMAN (H).**  
Work with people, communities, social systems  
*(teacher, manager, doctor, nanny, salesperson, psychologist, social worker)*.

---

**4. HUMANâ€“SIGN SYSTEMS (S).**  
Work with languages, signs, symbols, codes, formulas  
*(accountant, programmer, operator, economist, translator, cashier)*.

---

**5. HUMANâ€“ARTISTIC IMAGE (A).**  
Work with artistic creation and representation of reality  
*(actor, conductor, painter, tailor, chef, musician, architect)*.

---

**6. HUMANâ€“BUSINESS (B).**  
A newer type reflecting labor market demand  
*(managers, brokers, dealers, auditors, entrepreneurs)*.
""")

        elif lang == "kz":
            st.title("ÐšÓ™ÑÑ–Ð±Ð¸ Ò›Ñ‹Ð·Ð¼ÐµÑ‚ Ñ‚Ò¯Ñ€Ð»ÐµÑ€Ñ–")
            st.markdown("""
**1. ÐÐ”ÐÐœâ€“Ð¢Ð†Ð Ð† Ð¢ÐÐ‘Ð˜Ò’ÐÐ¢ (Ð¢).**  
Ó¨ÑÑ–Ð¼Ð´Ñ–ÐºÑ‚ÐµÑ€Ð¼ÐµÐ½, Ð¶Ð°Ð½ÑƒÐ°Ñ€Ð»Ð°Ñ€Ð¼ÐµÐ½, Ð¼Ð¸ÐºÑ€Ð¾Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð¼Ð´ÐµÑ€Ð¼ÐµÐ½ Ð¶Ó™Ð½Ðµ Ð¾Ð»Ð°Ñ€Ð´Ñ‹Ò£ Ñ‚Ñ–Ñ€ÑˆÑ–Ð»Ñ–Ðº Ð¶Ð°Ò“Ð´Ð°Ð¹Ð»Ð°Ñ€Ñ‹Ð¼ÐµÐ½ Ð¶Ò±Ð¼Ñ‹Ñ  
*(Ð°Ð³Ñ€Ð¾Ð½Ð¾Ð¼, Ð²ÐµÑ‚ÐµÑ€Ð¸Ð½Ð°Ñ€, Ð¼Ð°Ð»ÑˆÑ‹, ÐºÐ¸Ð½Ð¾Ð»Ð¾Ð³, Ñ„ÐµÑ€Ð¼ÐµÑ€, Ð³ÐµÐ¾Ð»Ð¾Ð³)*.

---

**2. ÐÐ”ÐÐœâ€“Ð¢Ð•Ð¥ÐÐ˜ÐšÐ Ð–Ó˜ÐÐ• Ó¨Ð›Ð† Ð¢ÐÐ‘Ð˜Ò’ÐÐ¢ (Ð¢).**  
Ó¨Ð»Ñ– Ð¶Ó™Ð½Ðµ Ñ‚ÐµÑ…Ð½Ð¸ÐºÐ°Ð»Ñ‹Ò› ÐµÒ£Ð±ÐµÐº Ð¾Ð±ÑŠÐµÐºÑ‚Ñ–Ð»ÐµÑ€Ñ–Ð¼ÐµÐ½ Ð¶Ò±Ð¼Ñ‹Ñ  
*(ÑÐ»ÐµÑÐ°Ñ€ÑŒ, Ð¼ÐµÑ…Ð°Ð½Ð¸Ðº, Ð¶Ò¯Ñ€Ð³Ñ–Ð·ÑƒÑˆÑ–, Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€, Ð°Ò“Ð°Ñˆ Ò±ÑÑ‚Ð°ÑÑ‹, Ð´Ó™Ð½ÐµÐºÐµÑ€Ð»ÐµÑƒÑˆÑ–, Ñ„Ð¸Ð·Ð¸Ðº, Ñ…Ð¸Ð¼Ð¸Ðº)*.

---

**3. ÐÐ”ÐÐœâ€“ÐÐ”ÐÐœ (Ð).**  
ÒšÐ¾Ò“Ð°Ð¼Ð´Ñ‹Ò› Ð¶Ò¯Ð¹ÐµÐ»ÐµÑ€Ð¼ÐµÐ½, Ò›Ð°ÑƒÑ‹Ð¼Ð´Ð°Ñ€Ð¼ÐµÐ½, Ó™Ñ€Ñ‚Ò¯Ñ€Ð»Ñ– Ð¶Ð°ÑÑ‚Ð°Ò“Ñ‹ Ð°Ð´Ð°Ð¼Ð´Ð°Ñ€Ð¼ÐµÐ½ Ð¶Ò±Ð¼Ñ‹Ñ  
*(Ð¼Ò±Ò“Ð°Ð»Ñ–Ð¼, Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€, Ð´Ó™Ñ€Ñ–Ð³ÐµÑ€, Ñ‚Ó™Ñ€Ð±Ð¸ÐµÑˆÑ–, ÑÐ°Ñ‚ÑƒÑˆÑ‹, Ó™Ð»ÐµÑƒÐ¼ÐµÑ‚Ñ‚Ñ–Ðº Ò›Ñ‹Ð·Ð¼ÐµÑ‚ÐºÐµÑ€, Ð¼Ð°ÑÑÐ°Ð¶Ð¸ÑÑ‚, Ð¿ÑÐ¸Ñ…Ð¾Ð»Ð¾Ð³)*.

---

**4. ÐÐ”ÐÐœâ€“Ð‘Ð•Ð›Ð“Ð†Ð›Ð†Ðš Ð–Ò®Ð™Ð• (Ð‘).**  
Ð¢Ñ–Ð»Ð´ÐµÑ€Ð¼ÐµÐ½, Ñ‚Ð°Ò£Ð±Ð°Ð»Ð°Ñ€Ð¼ÐµÐ½, Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ð°Ð»Ð°Ñ€Ð¼ÐµÐ½ Ð¶Ò±Ð¼Ñ‹Ñ  
*(Ð±ÑƒÑ…Ð³Ð°Ð»Ñ‚ÐµÑ€, Ð±Ð°Ò“Ð´Ð°Ñ€Ð»Ð°Ð¼Ð°ÑˆÑ‹, ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸ÑÑ‚, Ð°ÑƒÐ´Ð°Ñ€Ð¼Ð°ÑˆÑ‹, ÐºÐ°ÑÑÐ¸Ñ€)*.

---

**5. ÐÐ”ÐÐœâ€“ÐšÓ¨Ð ÐšÐ•Ðœ Ð‘Ð•Ð™ÐÐ• (Ðš).**  
Ð¨Ñ‹Ò“Ð°Ñ€Ð¼Ð°ÑˆÑ‹Ð»Ñ‹Ò›, Ó©Ð½ÐµÑ€ Ð°Ñ€Ò›Ñ‹Ð»Ñ‹ ÑˆÑ‹Ð½Ð´Ñ‹Ò›Ñ‚Ñ‹ Ð±ÐµÐ¹Ð½ÐµÐ»ÐµÑƒ  
*(Ó™Ñ€Ñ‚Ñ–Ñ, Ð´Ð¸Ñ€Ð¸Ð¶ÐµÑ€, ÑÑƒÑ€ÐµÑ‚ÑˆÑ–, Ñ‚Ñ–Ð³Ñ–Ð½ÑˆÑ–, Ð°ÑÐ¿Ð°Ð·, Ð¼ÑƒÐ·Ñ‹ÐºÐ°Ð½Ñ‚, ÑÓ™ÑƒÐ»ÐµÑ‚ÑˆÑ–)*.

---

**6. ÐÐ”ÐÐœâ€“Ð‘Ð˜Ð—ÐÐ•Ð¡ (Ð‘).**  
Ð•Ò£Ð±ÐµÐº Ð½Ð°Ñ€Ñ‹Ò“Ñ‹Ð½Ñ‹Ò£ ÑÒ±Ñ€Ð°Ð½Ñ‹ÑÑ‹Ð½Ð° Ð±Ð°Ð¹Ð»Ð°Ð½Ñ‹ÑÑ‚Ñ‹ Ð¶Ð°Ò£Ð° Ð±Ð°Ò“Ñ‹Ñ‚  
*(Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€Ð»ÐµÑ€, Ð±Ñ€Ð¾ÐºÐµÑ€Ð»ÐµÑ€, Ð´Ð¸Ð»ÐµÑ€Ð»ÐµÑ€, Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð»Ð°Ñ€, ÐºÓ™ÑÑ–Ð¿ÐºÐµÑ€Ð»ÐµÑ€)*.
""")
        # download PDF button for tab1
        if st.button({"ru": "Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð² PDF", "en": "Save results to PDF", "kz": "ÐÓ™Ñ‚Ð¸Ð¶ÐµÐ½Ñ– PDF-Ò›Ð° ÑÐ°Ò›Ñ‚Ð°Ñƒ"}[lang]):
            if "tab1_results" in st.session_state and st.session_state["tab1_results"] is not None:
                pdf_buf = save_tab1_results_to_pdf(st.session_state["tab1_results"], lang)
                st.download_button(
                    label={"ru": "Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ PDF", "en": "Download PDF", "kz": "Ð–Ò¯ÐºÑ‚ÐµÑƒ PDF"}[lang],
                    data=pdf_buf,
                    file_name="tab1_results.pdf",
                    mime="application/pdf"
                )
            else:
                st.warning({"ru": "ÐÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ", "en": "No results to save", "kz": "Ð¡Ð°Ò›Ñ‚Ð°ÑƒÒ“Ð° Ð½Ó™Ñ‚Ð¸Ð¶Ðµ Ð¶Ð¾Ò›"}[lang])

# ------------------------
# TAB 2 - Open questions
# ------------------------
with tabs[1]:
    with st.form("open_questions_form"):
        user_answers = [st.text_input(q, key=f"answer_{i}") for i, q in enumerate(ld["questions"])]
        submit_tab2 = st.form_submit_button(t["get_answer"])

    if submit_tab2:
        ai_response = get_ai_response(user_answers)
        st.session_state["tab2_ai_response"] = ai_response

    if "tab2_ai_response" in st.session_state:
        st.write(t["ai_response"])
        st.write(st.session_state["tab2_ai_response"])

        # ÐºÐ½Ð¾Ð¿ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ (ÑÐºÐ°Ñ‡Ð°Ñ‚ÑŒ) â€” Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ PDF Ð¸ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ½Ð¾Ð¿ÐºÑƒ
        pdf_buffer = save_tab2_results_to_pdf(
            ld["questions"],
            [st.session_state.get(f"answer_{i}", "") for i in range(len(ld["questions"]))],
            st.session_state["tab2_ai_response"],
            lang
        )
        st.download_button(
            label={"ru": "Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð² PDF", "en": "Save as PDF", "kz": "PDF ÑÐ°Ò›Ñ‚Ð°Ñƒ"}[lang],
            data=pdf_buffer,
            file_name="tab2_results.pdf",
            mime="application/pdf"
        )

# ------------------------
# TAB 3 - AI career (RAG only)
# ------------------------
with tabs[2]:
    with st.form("career_form"):
        st.title(t["advisor"])
        student_question = st.text_area(t["student_question"], height=100, key="student_q")
        submit_tab3 = st.form_submit_button(t["get_advice"])

    if submit_tab3:
        rag_answer = generate_rag_career_advice(student_question, embedder, annoy_index, texts)
        st.session_state["tab3_rag"] = rag_answer
        # save student question into session for PDF
        st.session_state["student_q"] = student_question

    if "tab3_rag" in st.session_state:
        st.subheader(t["rag_model"])
        st.write(st.session_state["tab3_rag"])
        pdf_buffer = save_tab3_results_to_pdf(
            st.session_state.get("student_q", ""),
            st.session_state["tab3_rag"],
            lang
        )
        st.download_button(
            label={"ru": "Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð² PDF", "en": "Save as PDF", "kz": "PDF ÑÐ°Ò›Ñ‚Ð°Ñƒ"}[lang],
            data=pdf_buffer,
            file_name="tab3_results.pdf",
            mime="application/pdf"
        )
